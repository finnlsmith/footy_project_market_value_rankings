{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/AssemblyHelpers.py:54: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from countries_languages import country_to_language\n",
    "\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "import numpy as np\n",
    "import re\n",
    "from transliterate import translit\n",
    "from unidecode import unidecode\n",
    "import Levenshtein\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import wikipediaapi\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import difflib\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import calendar\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import AssemblyHelpers\n",
    "#from AssemblyHelpers import find_money_info_from_name\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_dataset(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "countries_codes = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/countries_and_codes.csv')\n",
    "\n",
    "\n",
    "#leagues value\n",
    "leagues_value = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/Most Updated Edited Transfermarkt Dataset.csv')\n",
    "#leagues value large \n",
    "leagues_value_large = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/most_updated_transfermarkt_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 1 Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyrillic_group = load_csv_dataset('CSVs of edge cases - for F/Group 1 - Filter Using Match Date/Cyrillic_Guys_Multi_found.csv')\n",
    "\n",
    "multiple_names_working = load_csv_dataset('CSVs of edge cases - for F/Group 1 - Filter Using Match Date/multiple_names_working.csv')\n",
    "\n",
    "multiple_names_large_dataset_0 = load_csv_dataset('CSVs of edge cases - for F/Group 1 - Filter Using Match Date/multiple_names_used_large_dataset.csv')\n",
    "\n",
    "online_lookup_reqd = load_csv_dataset('CSVs of edge cases - for F/Group 1 - Filter Using Match Date/Online lookup required - multiple names found.csv')\n",
    "\n",
    "match_date_filter_guys = load_csv_dataset('CSVs of edge cases - for F/Group 1 - Filter Using Match Date/match_date_multi_guys.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions i need \n",
    "from fuzzywuzzy import process\n",
    "from Levenshtein import distance\n",
    "\n",
    "#tokens match one\n",
    "\n",
    "def check_tokens(this_jersey, match):\n",
    "    jersey_tokens = this_jersey.lower().split()\n",
    "    match_tokens = match.lower().split()\n",
    "    \n",
    "    if all(token in match_tokens for token in jersey_tokens):\n",
    "        return True\n",
    "    elif all(token in jersey_tokens for token in match_tokens) and len(jersey_tokens) == len(match_tokens) + 1:\n",
    "        return True\n",
    "    elif all(token in match_tokens for token in jersey_tokens) and len(jersey_tokens) > len(match_tokens):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def filter_multi_word_matches_by_jersey_tokens(jersey_tokens, potential_matches):\n",
    "    filtered_matches = []\n",
    "\n",
    "    for match in potential_matches:\n",
    "        # Split each match into tokens\n",
    "        match_tokens = match.split()\n",
    "\n",
    "        # Count the number of tokens that start with each character in jersey_tokens\n",
    "        match_token_start_chars = {token[0] for token in match_tokens}\n",
    "\n",
    "        # Check if the match contains at least one token for each character in jersey_tokens\n",
    "        if all(token[0] in match_token_start_chars for token in jersey_tokens):\n",
    "            filtered_matches.append(match)\n",
    "\n",
    "    return filtered_matches\n",
    "\n",
    "\n",
    "def vet_tokens_names(name, player):\n",
    "    player_original = player.copy()\n",
    "    original_name_tokens = name.split(' ')\n",
    "    #print(original_name_tokens)\n",
    "    for player_individual in player:\n",
    "        #print(player)\n",
    "        this_player_tokens = player_individual.split(' ')\n",
    "        \n",
    "        for token in original_name_tokens:\n",
    "            if token == '':\n",
    "                0==0\n",
    "            else:\n",
    "                first_letter = token[0]\n",
    "                #print(initial_token)\n",
    "                token_found = False\n",
    "                for token_player in this_player_tokens:\n",
    "                    if token_player.startswith(first_letter):\n",
    "                        \n",
    "                        if Levenshtein.distance(token_player, token) >= len(token_player):\n",
    "                            #print(f'did not match {token_player} with {token}')\n",
    "                            0==0\n",
    "                        else:\n",
    "                            #print(f'matched {token_player} with {token}')\n",
    "                            #print(token_player)\n",
    "                            token_found = True\n",
    "                            break\n",
    "                if not token_found:\n",
    "                    #print(player)\n",
    "                    if player_individual in player:\n",
    "                        player.remove(player_individual)\n",
    "    #print('banana', player)\n",
    "    if player  == []:\n",
    "        player = player_original\n",
    "        #print('razz', player)\n",
    "        for player_individual in player:\n",
    "            this_player_tokens = re.split(r'\\s+|-|–', player_individual)\n",
    "            #print('apple', this_player_tokens)\n",
    "            for token in original_name_tokens:\n",
    "                if token == '':\n",
    "                    0==0\n",
    "                else:\n",
    "                    first_letter = token[0]\n",
    "                    token_found = False\n",
    "                    for token_player in this_player_tokens:\n",
    "                        if token_player.startswith(first_letter):\n",
    "                            #print('pine', token_player)\n",
    "                            if Levenshtein.distance(token_player, token) >= len(token_player):\n",
    "                                #print(f'did not match {token_player} with {token}')\n",
    "                                0==0\n",
    "                            else:\n",
    "                                #print(f'matched {token_player} with {token}')\n",
    "                                #print(token_player)\n",
    "                                token_found = True\n",
    "                                break\n",
    "                if not token_found:\n",
    "                    player.remove(player_individual)\n",
    "                    break\n",
    "\n",
    "    #print(player)\n",
    "    return player\n",
    "\n",
    "def jersey_has_initial(string):\n",
    "    initials = set(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
    "    for i in range(len(string)):\n",
    "        if string[i] in initials:\n",
    "            # Check if it's not the last character in the string\n",
    "            if i < len(string) - 1:\n",
    "                # Check if it's followed by a space or is the last character\n",
    "                if string[i + 1] == ' ' or i == len(string) - 1:\n",
    "                    return True\n",
    "            # Check if it's the last character in the string\n",
    "            elif i == len(string) - 1:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# def standalone_initials(input_string):\n",
    "#     # Split the string by spaces\n",
    "#     words = input_string.split()\n",
    "    \n",
    "#     # Initialize a set to store standalone initials\n",
    "#     standalone_initials = set()\n",
    "    \n",
    "#     # Iterate through each word\n",
    "#     for word in words:\n",
    "#         # If the word is a single character, add it to the set\n",
    "#         if len(word) == 1:\n",
    "#             standalone_initials.add(word)\n",
    "#         # If the word is longer than one character, check if it's standalone, then add its initial\n",
    "#         elif len(word) > 1 and \" \" not in word:\n",
    "#             standalone_initials.add(word[0])\n",
    "    \n",
    "#     # Convert the set to a list and return\n",
    "#     return list(standalone_initials)\n",
    "def standalone_initials(input_string):\n",
    "    # Split the string by spaces\n",
    "    words = input_string.split()\n",
    "    \n",
    "    # Initialize a set to store standalone initials\n",
    "    standalone_initials = set()\n",
    "    \n",
    "    # Iterate through each word\n",
    "    for word in words:\n",
    "        # If the word is a single character, add it to the set\n",
    "        if len(word) == 1:\n",
    "            standalone_initials.add(word)\n",
    "        # If the word is longer than one character and doesn't contain spaces,\n",
    "        # add its initial to the set\n",
    "        elif len(word) == 2 and \" \" not in word:\n",
    "            standalone_initials.add(word[0])\n",
    "    \n",
    "    # Convert the set to a list and return\n",
    "    return list(standalone_initials)\n",
    "\n",
    "\n",
    "def find_close_matches_variable(this_jersey, dataset_nationality, threshold):\n",
    "    \"\"\"\n",
    "    Find close matches of `this_jersey` in `dataset_nationality` using Levenshtein distance.\n",
    "\n",
    "    Args:\n",
    "    - this_jersey (str): The string to find close matches for.\n",
    "    - dataset_nationality (list): List of strings to search for close matches in.\n",
    "    - threshold (int): Minimum similarity score required for a match (default is 90).\n",
    "\n",
    "    Returns:\n",
    "    - List of strings from `dataset_nationality` that are close matches to `this_jersey`.\n",
    "    \"\"\"\n",
    "    close_matches = process.extract(this_jersey, dataset_nationality, limit=None)\n",
    "    return [match[0] for match in close_matches if match[1] >= threshold]\n",
    "\n",
    "#threshold match one \n",
    "def threshold_player_match(this_jersey, dataset_nationality):\n",
    "    THRESHOLD_NUM = 89\n",
    "    #stops when it returns a name.\n",
    "    #if it doesnt find a match keep lowering the threshold until you find a match\n",
    "    #but if you get to threshold of like 50 first you stop and just abandon ship    \n",
    "\n",
    "    # Loop until someone is found or threshold goes below 50\n",
    "    while THRESHOLD_NUM >= 50:\n",
    "        matches = find_close_matches_variable(this_jersey, dataset_nationality, THRESHOLD_NUM)\n",
    "        if matches:\n",
    "            #print(f\"Player is {this_jersey}. Found matches: {matches}. threshold is {THRESHOLD_NUM}\")\n",
    "            return matches, THRESHOLD_NUM\n",
    "            #break\n",
    "        else:\n",
    "            THRESHOLD_NUM -= 1\n",
    "\n",
    "    # If threshold reaches below 50 without finding any matches\n",
    "    if THRESHOLD_NUM < 50:\n",
    "        return [f\"No matches found even with the lowest threshold.\"], this_jersey #jersey was {this_jersey}\n",
    "\n",
    "#MATCH DATE FILTER \n",
    "def filter_using_date_of_match(candidate_list_of_names_input, nationality_input, matchdate_Input, SALARY_BOOLEAN): \n",
    "\n",
    "    FILTERED_NAMES_USING_MATCH_DATE = AssemblyHelpers.multiNameMatchDateLookup(candidate_list_of_names_input, nationality_input, matchdate_Input) \n",
    "\n",
    "    #print('in fudom', type(FILTERED_NAMES_USING_MATCH_DATE))\n",
    "    #1 MATCH\n",
    "    if isinstance(FILTERED_NAMES_USING_MATCH_DATE, str) or isinstance(FILTERED_NAMES_USING_MATCH_DATE, np.str_): #YELLOW 3\n",
    "        #print('were here', FILTERED_NAMES_USING_MATCH_DATE)\n",
    "        #print('were in fudom in the right place')\n",
    "        #NAME_FOR_SELENIUM_SEARCH = FILTERED_NAMES_USING_MATCH_DATE\n",
    "        # MONEY_FOUND_ONLINE = useSeleniumToFindMoney(NAME_FOR_SELENIUM_SEARCH, nationality_input, matchdate_Input, SALARY_BOOLEAN)\n",
    "        # print('made it out of using selenium')\n",
    "        # money_thisplayer = [MONEY_FOUND_ONLINE, f'Online WAS Lookup Required - salary boolean is {SALARY_BOOLEAN}', True, False]\n",
    "        money_thisplayer = [0, 'Lookup Required', True, False]\n",
    "        return money_thisplayer, FILTERED_NAMES_USING_MATCH_DATE\n",
    "    #MULTIPLE MATCHES\n",
    "    elif(len(FILTERED_NAMES_USING_MATCH_DATE) >= 2):\n",
    "        print(FILTERED_NAMES_USING_MATCH_DATE, type(FILTERED_NAMES_USING_MATCH_DATE), type(FILTERED_NAMES_USING_MATCH_DATE) == str)\n",
    "        money_thisplayer = [0, F'FILTERING USING MATCH DATE LEFT MULTIPLE RESULTS: {FILTERED_NAMES_USING_MATCH_DATE}', True, False]\n",
    "        return money_thisplayer, FILTERED_NAMES_USING_MATCH_DATE\n",
    "    #0 MATCHES\n",
    "    elif(len(FILTERED_NAMES_USING_MATCH_DATE) == 0):\n",
    "        money_thisplayer = [0, F'FILTERING USING MATCH DATE LEFT 0 RESULTS. BEFORE FILTERING, CANDIDATE NAMES WERE {candidate_list_of_names_input}', True, False]\n",
    "        return money_thisplayer, ''\n",
    "\n",
    "#FINDING MONEY INFO USSING PLAYER NAME\n",
    "def tryToFindPlayerMoney(\n",
    "        DATABASE_RETURN_MESSAGE, #what the DB said when trying to find money info\n",
    "        NAME_TO_FIND, #the name it found in the DB (name_match[0] originally)\n",
    "        NATIONALITY_INPUT_PLAYER, #natl_test\n",
    "        DATE_INPUT_MATCH, #input_year_test\n",
    "        SALARY_BOOLEAN, #IF TRUE, SALARIES. OTHERWISE VALUES\n",
    "        ORIGINAL_SEARCH_NAME #name_match[2]\n",
    "        ):\n",
    "\n",
    "    if((DATABASE_RETURN_MESSAGE == \"not in DB any of 3 seasons.\") or (DATABASE_RETURN_MESSAGE == \"asswipe was in DB in before or after season\")):\n",
    "        print('newwwnewnenwenewnwenwenwew', DATABASE_RETURN_MESSAGE)\n",
    "        \n",
    "        if DATABASE_RETURN_MESSAGE == 'asswipe was in DB in before or after season':\n",
    "            money_thisplayer = [0, 'Was in  DB before or after season', True, True]\n",
    "            return money_thisplayer\n",
    "        \n",
    "\n",
    "        INTERNET_LOOKUP_RESULTING_NAMES = AssemblyHelpers.false_name_match_lookup(ORIGINAL_SEARCH_NAME, NATIONALITY_INPUT_PLAYER)\n",
    "        NUM_NAMES_REMAINING = len(list(INTERNET_LOOKUP_RESULTING_NAMES))\n",
    "        print(INTERNET_LOOKUP_RESULTING_NAMES)\n",
    "        #1 MATCH\n",
    "        if(NUM_NAMES_REMAINING == 1):\n",
    "            #FIND INFO USING SELENIUM\n",
    "            # NAME_FOR_SELENIUM_SEARCH = next(iter(INTERNET_LOOKUP_RESULTING_NAMES))\n",
    "            # MONEY_FOUND_ONLINE = useSeleniumToFindMoney(NAME_FOR_SELENIUM_SEARCH, NATIONALITY_INPUT_PLAYER, DATE_INPUT_MATCH, SALARY_BOOLEAN)\n",
    "            # money_thisplayer = [MONEY_FOUND_ONLINE, f'Online WAS Lookup Required - salary boolean is {SALARY_BOOLEAN}', True, False]\n",
    "            money_thisplayer = [0, 'Lookup Required', True, False]\n",
    "            return money_thisplayer\n",
    "        #MULTIPLE MATCHES\n",
    "        elif(NUM_NAMES_REMAINING >= 2):\n",
    "            print('goes to FUDOM')\n",
    "            #FILTER THE NAMES USING THE DATE OF THE MATCH\n",
    "            list_to_filter_with_match_date = list(INTERNET_LOOKUP_RESULTING_NAMES)\n",
    "            #NEW FUNCTION 3 \n",
    "            money_thisplayer, name_results = filter_using_date_of_match(list_to_filter_with_match_date, NATIONALITY_INPUT_PLAYER, DATE_INPUT_MATCH, SALARY_BOOLEAN) \n",
    "            return money_thisplayer\n",
    "        #0 MATCHES\n",
    "        elif(NUM_NAMES_REMAINING == 0):\n",
    "            #This is return case 9\n",
    "            money_thisplayer = [0, 'Online Lookup Required', True, False] \n",
    "            return money_thisplayer\n",
    "    \n",
    "    else:\n",
    "        money_thisplayer = [0, 'Online Lookup Required', True, False]\n",
    "        return money_thisplayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success + Working + returned a set of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_matches_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_matches_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in multiple_names_working.iterrows():\n",
    "\n",
    "\n",
    "for i in range(679, 692):\n",
    "    status = 'Fail'\n",
    "    index = i\n",
    "    row = match_date_filter_guys.iloc[index]\n",
    "    jersey = row['ORIGINAL JERSEY'] #row['English Name']\n",
    "    if jersey == 'J Gudmunds son':\n",
    "        jersey = 'Jóhann Berg Gudmundsson'\n",
    "    elif jersey == 'Ahmad Al Dhe':\n",
    "        jersey = 'Ahmad Al-Dhefiri'\n",
    "    elif jersey == 'A Nagy':\n",
    "        jersey = 'Ádám Nagy'\n",
    "    elif jersey == 'Al Pereira':\n",
    "        jersey = 'Álvaro Pereira'\n",
    "    elif jersey == 'Lo Chih-en':\n",
    "        jersey = 'ChihEn Lo'\n",
    "    elif jersey == 'Faisal Al Harbi':\n",
    "        jersey = 'Faisal Zayed'\n",
    "    elif jersey == 'Ch Rubio':\n",
    "        jersey = 'Jesús Rubio'\n",
    "    elif jersey == 'M-l Büchel':\n",
    "        jersey = 'M Büchel'\n",
    "    elif jersey == 'O Romero':\n",
    "        jersey = 'Ó Romero'\n",
    "    # if i == 65 or i == 84:\n",
    "    #     jersey = 'A C González'\n",
    "    # elif i == 73:\n",
    "    #     jersey = 'P Quiñonez'\n",
    "    # elif i == 420:\n",
    "    #     jersey = 'E Benitez'\n",
    "    name_set = eval(row['Name(s) Found']) #Match(es) Found\n",
    "    this_country_code = row['Team Country Code'] #row['Country Code']\n",
    "    \n",
    "    #print(f'**{index}** {jersey}')\n",
    "    season = row['Season']\n",
    "    name_key = f\"{jersey}_{season}\"\n",
    "\n",
    "    if name_key in names_matches_dict.keys():\n",
    "        correct_names = names_matches_dict[name_key]\n",
    "        print(f'***{i}*** - {jersey} found in dict. names found: {correct_names}')\n",
    "        # if i == 47:\n",
    "        #     correct_names = ['Franklin Lucena']\n",
    "        if len(correct_names) >= 2:\n",
    "            multi_list = correct_names\n",
    "            correct_names = []\n",
    "            status = 'Multi'\n",
    "        else:\n",
    "            status = 'Success'\n",
    "    else:\n",
    "\n",
    "        country_name = countries_codes[countries_codes[' Code'] == this_country_code]['Country'].unique()[0]\n",
    "        dataset_nationality = leagues_value[leagues_value['Team 1 Code'] == this_country_code]['Name'].unique()\n",
    "        dataset_nationality_unidecoded = {unidecode(name) for name in dataset_nationality}\n",
    "\n",
    "        correct_names = []\n",
    "        for name_single in name_set:\n",
    "            if check_tokens(jersey, name_single):\n",
    "                correct_names.append(name_single)\n",
    "            else:\n",
    "                0==0\n",
    "        if len(correct_names) >= 2:\n",
    "            #print(f'first round matching. multiple names for {jersey}. {correct_names}')\n",
    "            status = 'Multi'\n",
    "            multi_list = correct_names\n",
    "        elif len(correct_names) == 1:\n",
    "            status = 'Success'\n",
    "        else:\n",
    "            correct_names_threshold = threshold_player_match(jersey, dataset_nationality)[0]\n",
    "            for name_threshold in correct_names_threshold:\n",
    "                if name_threshold in name_set:\n",
    "                    correct_names_threshold.remove(name_threshold)\n",
    "\n",
    "            if len(correct_names_threshold) >= 2:\n",
    "                for name in correct_names_threshold:\n",
    "                    if check_tokens(jersey, name_single):\n",
    "                        correct_names.append(name_single)\n",
    "                    else:\n",
    "                        0==0\n",
    "                if len(correct_names) >= 2:\n",
    "                    0==0\n",
    "                elif len(correct_names) == 1:\n",
    "                    status = 'Success'\n",
    "                else:\n",
    "                    last_name = jersey.split(' ')[-1]\n",
    "                    last_name_threshold_matches = threshold_player_match(last_name, dataset_nationality)[0]\n",
    "                    if len(last_name_threshold_matches) >= 2:\n",
    "                        if jersey_has_initial(jersey):\n",
    "                            name_initials = standalone_initials(jersey)\n",
    "                            for initial in name_initials:\n",
    "                                for name in last_name_threshold_matches:\n",
    "                                    name_tokens = name.split(' ')\n",
    "                                    for token in name_tokens:\n",
    "                                        if token != last_name and token.startswith(initial):\n",
    "                                            correct_names.append(name)\n",
    "                            \n",
    "                            if len(correct_names) >= 2:\n",
    "                                #print(f'threshold matching last names & initials. multiple names for {jersey}. {correct_names}. Game is {row['Match']} on {row['Date']}')\n",
    "                                status = 'Multi'\n",
    "                                multi_list = correct_names\n",
    "                            elif len(correct_names) == 1:\n",
    "                                status = 'Success'\n",
    "                            else:\n",
    "                                print(f'threshold matching last names & initials left nobody. {jersey}')\n",
    "\n",
    "                    elif len(last_name_threshold_matches) == 1:\n",
    "                        status = 'Success'\n",
    "                        correct_names = last_name_threshold_matches\n",
    "                    else:\n",
    "                        print(f' {jersey}. no similar last names.')\n",
    "                    #just use the last name, find all players with the last name. \n",
    "                        #then if theres an initial use that. \n",
    "                        #then if its still multi, match \n",
    "\n",
    "            elif len(correct_names_threshold) == 1:\n",
    "                correct_names = correct_names_threshold\n",
    "                status = 'Success'\n",
    "            else:\n",
    "                correct_names = vet_tokens_names(jersey, name_set)\n",
    "                if len(correct_names) >= 2:\n",
    "                    #print(f'3rd round matching. multiple names for {jersey}. {correct_names}')\n",
    "                    status = 'Multi'\n",
    "                    multi_list = correct_names\n",
    "                elif len(correct_names) == 1:\n",
    "                    status = 'Success'\n",
    "                else:\n",
    "                    print('no results for ', jersey)\n",
    "\n",
    "        if status == 'Success':\n",
    "            if jersey_has_initial:\n",
    "                name_initials = standalone_initials(jersey)\n",
    "                \n",
    "                for initial in name_initials:\n",
    "                    for name in correct_names:\n",
    "                        found = False\n",
    "                        name_tokens = name.split(' ')\n",
    "                        last_name = name_tokens[-1]\n",
    "                        for token in name_tokens:\n",
    "                            if token != last_name and token.startswith(initial):\n",
    "                                #print(token)\n",
    "                                found = True\n",
    "                        if found == False:\n",
    "                            correct_names.remove(name)\n",
    "                if len(correct_names) >= 2:\n",
    "                    status = 'Multi'\n",
    "                elif len(correct_names) == 1:\n",
    "                    0==0\n",
    "                else:\n",
    "                    last_name = jersey.split(' ')[-1]\n",
    "                    last_name_threshold_matches = threshold_player_match(last_name, dataset_nationality)[0]\n",
    "                    if len(last_name_threshold_matches) >= 2:\n",
    "                        if jersey_has_initial(jersey):\n",
    "                            name_initials = standalone_initials(jersey)\n",
    "                            for initial in name_initials:\n",
    "                                for name in last_name_threshold_matches:\n",
    "                                    name_tokens = name.split(' ')\n",
    "                                    last_name = name_tokens[-1]\n",
    "                                    for token in name_tokens:\n",
    "                                        if token != last_name and token.startswith(initial):\n",
    "                                            correct_names.append(name)\n",
    "                            \n",
    "                            if len(correct_names) >= 2:\n",
    "                                #print(f'threshold matching last names & initials. multiple names for {jersey}. {correct_names}. Game is {row['Match']} on {row['Date']}')\n",
    "                                status = 'Multi'\n",
    "                                multi_list = correct_names\n",
    "                            elif len(correct_names) == 1:\n",
    "                                status = 'Success'\n",
    "                            else:\n",
    "                                print(f'threshold matching last names & initials left nobody. {jersey}')\n",
    "        elif status == 'Multi':\n",
    "\n",
    "            for name in multi_list:\n",
    "                name_records_seasons = leagues_value[leagues_value['Name'] == name]['Season'].unique()\n",
    "                #print(season, name, name_records_seasons)\n",
    "                if not any(abs(s - season) <= 1 for s in name_records_seasons):\n",
    "                    multi_list.remove(name)\n",
    "            if len(multi_list) >= 2:\n",
    "                0==0\n",
    "            elif len(multi_list) == 1:\n",
    "                correct_names = multi_list\n",
    "                status = 'Success'\n",
    "            else:\n",
    "                0==0 #that means none of the people u found had records near the year of the game \n",
    "        \n",
    "        if status == 'Success':\n",
    "            0==0\n",
    "            print(f'***{i}*** - ✓ - ADDED TO DICT SINGLE - {jersey}:{correct_names}') #correct_names\n",
    "            #if the name has an initial and theres no token in the single match that starts with that initial\n",
    "            #you have to call it a fail and print the threshold match of the last name.\n",
    "\n",
    "            names_matches_dict[name_key] = correct_names\n",
    "\n",
    "        elif status == 'Multi':\n",
    "\n",
    "            print(f'***{i}*** - ✓ ---- ADDED TO DICT MULTI ---- {jersey}:{multi_list}') #multi_list\n",
    "            names_matches_dict[name_key] = multi_list\n",
    "        else:\n",
    "            print(f'- FAIL - FAIL - ****{i}**** FAIL – FAIL – ', jersey)\n",
    "\n",
    "    if status == 'Multi':\n",
    "        print('filtering using match date...') #if multi, filter using match date \n",
    "        filtered_names_match_date = filter_using_date_of_match(multi_list, row['Nationality'], row['Date'], False)[1]\n",
    "        if type(filtered_names_match_date) == str:\n",
    "            correct_names = filtered_names_match_date\n",
    "            status = 'Success'\n",
    "        else:\n",
    "            multi_list = filtered_names_match_date\n",
    "\n",
    "\n",
    "    if status == 'Success':\n",
    "        new_row = {\n",
    "            'Match ID': row['Match ID'],\n",
    "            'Match': row['Match'],\n",
    "            'Date': row['Date'],\n",
    "            'Competition': row['Competition'],\n",
    "            'Nationality': row['Nationality'],\n",
    "            'Country Code': this_country_code,\n",
    "            'ORIGINAL JERSEY': jersey,\n",
    "            'Names_Found': correct_names,\n",
    "            'Season': season,\n",
    "            'Status': status\n",
    "        }\n",
    "    elif status == 'Multi':\n",
    "        new_row = {\n",
    "            'Match ID': row['Match ID'],\n",
    "            'Match': row['Match'],\n",
    "            'Date': row['Date'],\n",
    "            'Competition': row['Competition'],\n",
    "            'Nationality': row['Nationality'],\n",
    "            'Country Code': this_country_code,\n",
    "            'ORIGINAL JERSEY': jersey,\n",
    "            'Names_Found': multi_list,\n",
    "            'Season': season,\n",
    "            'Status': status\n",
    "        }\n",
    "    else:\n",
    "        new_row = {\n",
    "            'Match ID': row['Match ID'],\n",
    "            'Match': row['Match'],\n",
    "            'Date': row['Date'],\n",
    "            'Competition': row['Competition'],\n",
    "            'Nationality': row['Nationality'],\n",
    "            'Country Code': this_country_code,\n",
    "            'ORIGINAL JERSEY': jersey,\n",
    "            'Names_Found': name_set,\n",
    "            'Season': season,\n",
    "            'Status': 'Fail'\n",
    "        }\n",
    "\n",
    "    multiple_matches_df = pd.concat([multiple_matches_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "        #once single add them to a dataset \n",
    "            #match ID\n",
    "            #match\n",
    "            #date\n",
    "            #competition\n",
    "            #season \n",
    "            #nationality\n",
    "            #country code\n",
    "            #jersey \n",
    "            #names found\n",
    "\n",
    "            #match case - single or multi or fail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['Match'], row['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_matches_df[multiple_matches_df['Status'] == 'Multi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_multi_dataset = multiple_matches_df\n",
    "big_multi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_multi_dataset.to_csv('match_date_multi_guys_MATCHES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STRATEGY - SUCCESS + WORKING\n",
    "\n",
    "    #for each name in the set \n",
    "    #check tokens \n",
    "        #if that leaves 1 name, finish\n",
    "\n",
    "        #if that leaves multiple names \n",
    "            #filter using the match date \n",
    "\n",
    "        #if that leaves 0 names\n",
    "            #do the threshold match \n",
    "\n",
    "                #if that leaves 1 name, finish\n",
    "\n",
    "\n",
    "                #if that leaves multiple names \n",
    "\n",
    "                    #filter using the match date \n",
    "\n",
    "                #if that leaves 0 names\n",
    "                    #do vet_tokens_names \n",
    "\n",
    "                    #if that leaves 1 name, finish\n",
    "\n",
    "                    #if that leaves multiple names \n",
    "\n",
    "                        #filter using the match date \n",
    "\n",
    "                    #if that leaves 0 names\n",
    "\n",
    "                        #????\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining success group CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path\n",
    "folder_path = 'Group 1 Working guys'\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store merged data\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over each CSV file and merge into one DataFrame\n",
    "for file in csv_files:\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(os.path.join(folder_path, file))\n",
    "    # Merge with existing data\n",
    "    merged_data = pd.concat([merged_data, df], ignore_index=True)\n",
    "\n",
    "# Write merged data to a new CSV file\n",
    "merged_data.to_csv('working_multiple_names_combined.csv', index=False)\n",
    "\n",
    "print(\"Merged data saved to 'working_multiple_names_combined.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
