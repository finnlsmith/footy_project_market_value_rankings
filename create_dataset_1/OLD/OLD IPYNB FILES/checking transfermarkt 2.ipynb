{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "import numpy as np\n",
    "import re\n",
    "from transliterate import translit\n",
    "from unidecode import unidecode\n",
    "\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INGESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_leagues = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/latest_transfermarkt_data_money_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "League\n",
       "Serie A                      9425\n",
       "EPL                          8360\n",
       "Turkish League               7883\n",
       "Ligue 1                      7683\n",
       "La Liga                      7404\n",
       "Portuguese First Division    6922\n",
       "Bundesliga                   6746\n",
       "Eredivisie                   6713\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_leagues['League'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cyrillic(input_string):\n",
    "    # Check if the string contains non-ASCII characters\n",
    "    return not input_string.isascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyrillic_to_latin(input_string):\n",
    "    try:\n",
    "        # Use the \"translit\" function to convert Cyrillic to Latin\n",
    "        latin_string = translit(input_string, 'ru', reversed=True)\n",
    "        return latin_string\n",
    "    except Exception as e:\n",
    "        # Handle exceptions, e.g., if the input is not valid Cyrillic\n",
    "        print(f\"Error: {e}\")\n",
    "        return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(array, final_tokens, ORIGINAL_STRING):\n",
    "    # Concatenate final tokens to form the expected full name\n",
    "    expected_name = ' '.join(final_tokens)\n",
    "    \n",
    "    # Filter names that start with the initial letter\n",
    "    filtered_names = [name for name in array if name.startswith(final_tokens[0])]\n",
    "    \n",
    "    if not filtered_names:\n",
    "        # Try switching the order of final tokens\n",
    "        filtered_names = [name for name in array if name.startswith(final_tokens[1])]\n",
    "        final_tokens = [final_tokens[1], final_tokens[0]]\n",
    "    \n",
    "    if not filtered_names:\n",
    "        return None  # No matching names found\n",
    "    \n",
    "    # Check if the ORIGINAL_STRING contains a backtick/apostrophe\n",
    "    has_backtick_apostrophe = \"'\" in ORIGINAL_STRING or \"`\" in ORIGINAL_STRING\n",
    "    \n",
    "    # Filter names based on the presence of a backtick/apostrophe\n",
    "    filtered_names = [name for name in filtered_names if \"'\" in name or \"`\" in name] if has_backtick_apostrophe else filtered_names\n",
    "    \n",
    "    if not filtered_names:\n",
    "        return None  # No matching names found\n",
    "    \n",
    "    # Calculate Levenshtein distance between the expected name and each remaining name\n",
    "    distances = [Levenshtein.distance(unidecode(expected_name), unidecode(name.replace(\" \", \"\"))) for name in filtered_names]\n",
    "    \n",
    "    # Find the index of the minimum distance\n",
    "    min_distance_index = distances.index(min(distances))\n",
    "    \n",
    "    # Return the name with the minimum distance\n",
    "    return filtered_names[min_distance_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string_newest_ii(input_string):\n",
    "    cleaned_string = re.sub(r'^\\d{1,2}[. ]', '', input_string)\n",
    "    tokens = cleaned_string.split()\n",
    "    final_string = \"\"\n",
    "\n",
    "    if len(tokens) >= 1 and not re.match(r'^[A-Za-zÀ-ÖØ-öø-ÿ]{2,}$', tokens[0]):\n",
    "        initial_match = re.match(r'^([A-Za-zÀ-ÖØ-öø-ÿ]+\\.)+$|[A-Za-zÀ-ÖØ-öø-ÿ]\\.$|[A-Za-zÀ-ÖØ-öø-ÿ]$', tokens[0])\n",
    "        if initial_match:\n",
    "            final_string += initial_match.group()\n",
    "\n",
    "    main_phrase = \" \".join(word for word in tokens if len(\"\".join(char for char in word if char.isalpha())) >= 2)\n",
    "    if main_phrase:\n",
    "        final_string += \" \" + main_phrase\n",
    "\n",
    "    if len(tokens) >= 2 and not re.match(r'^[A-Za-zÀ-ÖØ-öø-ÿ]{2,}$', tokens[1]):\n",
    "        end_initial_match = re.match(r'^([A-Za-zÀ-ÖØ-öø-ÿ]+\\.)+$|[A-Za-zÀ-ÖØ-öø-ÿ]\\.$|[A-Za-zÀ-ÖØ-öø-ÿ]$', tokens[1])\n",
    "        if end_initial_match:\n",
    "            final_string = \"\".join(char for char in end_initial_match.group() if char.isalpha()) + \" \" + final_string\n",
    "\n",
    "    # Check if the final phrase ends in a period\n",
    "    if final_string.endswith(\".\"):\n",
    "        # Extract the last word, remove the period, and move it to the start of final_string\n",
    "        last_word = final_string.split()[-1].rstrip('.')\n",
    "        final_string = last_word + \" \" + final_string\n",
    "\n",
    "        # Remove the last word from the end of the string\n",
    "        final_string = ' '.join(final_string.split()[:-1])\n",
    "\n",
    "        final_string = final_string.strip()\n",
    "\n",
    "    # Separate the final string by \" \" and remove non-alphabet characters for each token\n",
    "    final_tokens = [re.sub(r'[^A-Za-zÀ-ÖØ-öø-ÿćč-]', '', token) for token in final_string.split()]\n",
    "\n",
    "    # If the first two tokens are the same, remove one token\n",
    "    if len(final_tokens) >= 2 and final_tokens[0] == final_tokens[1]:\n",
    "        final_tokens.pop(0)\n",
    "\n",
    "    joined_string = \" \".join(final_tokens)\n",
    "    return joined_string, final_tokens\n",
    "\n",
    "    #return \" \".join(final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_name(match_apostrophes_accounted, lastname_match):\n",
    "    # Check if lastname_match is part of match_apostrophes_accounted\n",
    "    if lastname_match in match_apostrophes_accounted:\n",
    "        # Split the string using lastname_match as the separator\n",
    "        first_name = match_apostrophes_accounted.split(lastname_match)[0].strip()\n",
    "        return first_name\n",
    "    else:\n",
    "        # Handle the case where lastname_match is not found in match_apostrophes_accounted\n",
    "        print(f\"{lastname_match} not found in {match_apostrophes_accounted}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_backticks(lastname_match, original_string_nojersey):\n",
    "    # Find the indices of backticks/apostrophes in the original string\n",
    "    special_indices = [i for i, char in enumerate(original_string_nojersey) if char in (\"`\", \"'\")]\n",
    "\n",
    "    # Add backticks in the corresponding places in the last name match\n",
    "    for index in special_indices:\n",
    "        # Check if the index is within the range of the last_name_match\n",
    "        if 0 <= index < len(lastname_match):\n",
    "            # Insert backtick in the appropriate position\n",
    "            lastname_match = lastname_match[:index] + original_string_nojersey[index] + lastname_match[index:]\n",
    "\n",
    "    return lastname_match\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_string_newEST(input_string, string_list, input_final_tokens, ORIGINAL_NAME_STRING):\n",
    "    #replace nationality name list with string_list\n",
    "    #replace string_for_search with input_string \n",
    "    #replace final_tokens with input_final_tokens\n",
    "    #replace input_string with ORIGINAL_NAME_STRING\n",
    "\n",
    "    closest_match = get_close_matches(input_string, string_list, n=1, cutoff=0.8)\n",
    "\n",
    "    closest_match_4 = []\n",
    "    closest_match_3 = []\n",
    "    closest_match_2 = []\n",
    "    index_match = \"\"\n",
    "    matching_indices = []\n",
    "\n",
    "    if closest_match:\n",
    "        #TIGHT CLOSE MATCH FUNCTION RETURNS A NAME\n",
    "        #print('0', closest_match[0], closest_match in string_list)\n",
    "        #RETURN HERE\n",
    "        return closest_match[0]\n",
    "    else:\n",
    "        #Reduce match constraints\n",
    "        closest_match_ii = get_close_matches(input_string, string_list)\n",
    "        #Produces a match\n",
    "        if closest_match_ii:\n",
    "            if((type(closest_match_ii) == list) & (len(closest_match_ii) >= 2)):\n",
    "                #Closest match II returns 1 name\n",
    "                original_string_nojersey = re.sub(r'^\\d+(\\.)?\\s*', '', ORIGINAL_NAME_STRING)\n",
    "                #Find best match from set of names\n",
    "                result_1 = find_best_match(closest_match_ii, input_final_tokens, original_string_nojersey)\n",
    "                if(pd.isna(result_1)):\n",
    "                    #none of the names from closest match ii were a good match\n",
    "                    0==0\n",
    "                else:\n",
    "                    #1 of the names from closest match ii were a good match\n",
    "                    #print('closest match ii best match: ' + result_1)\n",
    "                    closest_match_ii = result_1\n",
    "                    #RETURN HERE\n",
    "                    return closest_match_ii\n",
    "            else:\n",
    "                #Closest match II returns 1 name\n",
    "                #print('1 match ' + closest_match_ii[0])\n",
    "                #RETURN HERE\n",
    "                return closest_match_ii[0]\n",
    "        else:\n",
    "            # no close matches\n",
    "            last_word = input_string.split()[-1]\n",
    "            #KREJCI CASE \n",
    "            if(last_word == 'Krejčí'):\n",
    "                match_krejci = get_close_matches(last_word, string_list, n=1, cutoff=0.380952)\n",
    "                if(type(match_krejci) == list):\n",
    "                    if(len(match_krejci) == 1):\n",
    "                        match_krejci = match_krejci[0]\n",
    "                        return match_krejci\n",
    "                    \n",
    "                \n",
    "                #HANDLED SAISS CASE HERE \n",
    "                # closest_match_3 = get_close_matches(last_word, nationality_name_list, n=1, cutoff=0.4)\n",
    "                # if(closest_match_3):\n",
    "                #     print('closest match 3 case match Saïss case')\n",
    "                #     0==0\n",
    "\n",
    "            \n",
    "            #if this is an initial you need to save it as an initial or a word start \n",
    "            #if(last_word)\n",
    "\n",
    "            # Return strings from the list if the last word is in those strings\n",
    "            matching_strings = [s for s in string_list if last_word in s]\n",
    "\n",
    "            if matching_strings:\n",
    "                if(len(matching_strings) == 1):\n",
    "                    #print('match string ' + matching_strings[0])\n",
    "                    #RETURN HERE\n",
    "                    return matching_strings[0]\n",
    "                else:\n",
    "                    #print(matching_strings)\n",
    "                    setofmatches = matching_strings\n",
    "                    \n",
    "        #elif(closest_match):       \n",
    "        if(closest_match):\n",
    "            #RETURN\n",
    "            print('1', closest_match[0], closest_match[0] in string_list)\n",
    "        elif(closest_match_ii):\n",
    "            if(type(closest_match_ii) == str):\n",
    "                print(closest_match_ii, closest_match_ii in string_list)\n",
    "            #RETURN\n",
    "            else:\n",
    "                print('ii', closest_match_ii[0], closest_match_ii[0] in string_list)\n",
    "        elif(closest_match_3):\n",
    "            #RETURN\n",
    "            print('3', closest_match_3[0], closest_match_3[0] in string_list)\n",
    "        elif(closest_match_2):\n",
    "            #RETURN\n",
    "            print('2', closest_match_2[0], closest_match_2[0] in string_list)\n",
    "        elif(closest_match_4):\n",
    "            #RETURN\n",
    "            print('4', closest_match_4[0], closest_match_4[0] in string_list)\n",
    "        elif(index_match != \"\"):\n",
    "            #RETURN\n",
    "            print('end ' + index_match + ORIGINAL_NAME_STRING, matching_indices)\n",
    "            return(index_match)\n",
    "        else:\n",
    "            #RETURN\n",
    "            return(\"No close match found.\")\n",
    "            #print(\"No close match found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_candidates(NAMESTRING, LISTCANDIDATES):\n",
    "    # Get the first token of the NAMESTRING\n",
    "    first_token = re.split(r'\\s', NAMESTRING)[0]\n",
    "\n",
    "    # Create a regex pattern for matching candidates that start with the first token\n",
    "    pattern = re.compile(fr'^{re.escape(first_token)}', re.IGNORECASE)\n",
    "\n",
    "    # Filter candidates based on the pattern\n",
    "    filtered_candidates = list(filter(lambda x: re.match(pattern, x), LISTCANDIDATES))\n",
    "\n",
    "    return filtered_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents_from_strings(input_array):\n",
    "    # Ensure the input is a numpy array\n",
    "    if not isinstance(input_array, np.ndarray) or input_array.dtype != np.dtype('O'):\n",
    "        raise ValueError(\"Input must be a NumPy array of strings\")\n",
    "\n",
    "    # Define a function to remove accents from a single string\n",
    "    def remove_accents_single_string(s):\n",
    "        return unidecode(s)\n",
    "\n",
    "    # Vectorize the function to apply it element-wise to the array\n",
    "    remove_accents_vectorized = np.vectorize(remove_accents_single_string)\n",
    "\n",
    "    # Apply the vectorized function to each element in the array\n",
    "    result_array = remove_accents_vectorized(input_array)\n",
    "\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_names_with_accents(target_name, name_array):\n",
    "    # Ensure the input is a numpy array\n",
    "    if not isinstance(name_array, np.ndarray) or name_array.dtype != np.dtype('O'):\n",
    "        raise ValueError(\"Input must be a NumPy array of strings\")\n",
    "\n",
    "    # Remove accents from the target name\n",
    "    target_name_without_accents = unidecode(target_name)\n",
    "\n",
    "    # Define a function to check if a name with accents matches the target name\n",
    "    def has_accent_match(name):\n",
    "        return unidecode(name) == target_name_without_accents\n",
    "\n",
    "    # Vectorize the function to apply it element-wise to the array\n",
    "    has_accent_match_vectorized = np.vectorize(has_accent_match)\n",
    "\n",
    "    # Apply the vectorized function to each element in the array\n",
    "    matching_names = name_array[has_accent_match_vectorized(name_array)]\n",
    "\n",
    "    if(len(matching_names) == 1):\n",
    "        return matching_names[0]\n",
    "\n",
    "    return matching_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophes_backticks(input_array):\n",
    "    # Ensure the input is a numpy array\n",
    "    if not isinstance(input_array, np.ndarray) or input_array.dtype != np.dtype('O'):\n",
    "        raise ValueError(\"Input must be a NumPy array of strings\")\n",
    "\n",
    "    # Define a function to remove apostrophes and backticks from a single string\n",
    "    def remove_chars_single_string(s):\n",
    "        return np.char.replace(np.char.replace(s, \"'\", ''), \"`\", '')\n",
    "\n",
    "    # Vectorize the function to apply it element-wise to the array\n",
    "    remove_chars_vectorized = np.vectorize(remove_chars_single_string)\n",
    "\n",
    "    # Apply the vectorized function to each element in the array\n",
    "    result_array = remove_chars_vectorized(input_array)\n",
    "\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_korean_name(name):\n",
    "    # Split the name into parts\n",
    "    parts = name.split()\n",
    "\n",
    "    # Check if the name has at least two parts\n",
    "    if len(parts) >= 2:\n",
    "        # Format the name as \"Ja-cheol Koo\"\n",
    "        transformed_name = f\"{parts[1].capitalize()}-{parts[0].capitalize()}\"\n",
    "        return transformed_name\n",
    "    else:\n",
    "        # Return the original name if it doesn't have at least two parts\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophes_backticks_single_string(input_string):\n",
    "    # Ensure the input is a string\n",
    "    if not isinstance(input_string, str):\n",
    "        raise ValueError(\"Input must be a string\")\n",
    "\n",
    "    # Define a function to remove apostrophes and backticks from a single string\n",
    "    def remove_chars_single_string(s):\n",
    "        return s.replace(\"'\", '').replace(\"`\", '')\n",
    "\n",
    "    # Apply the function to the input string\n",
    "    result_string = remove_chars_single_string(input_string)\n",
    "\n",
    "    return result_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_names_first_initial_lastname(database, search_string):\n",
    "    # Filter out non-string elements from the database\n",
    "    string_database = [str(item) for item in database if isinstance(item, str)]\n",
    "    \n",
    "    # Convert search string to lowercase for case-insensitive matching\n",
    "    search_string_lower = search_string.lower()\n",
    "    \n",
    "    # Split the search string into parts\n",
    "    parts = search_string_lower.split()\n",
    "    \n",
    "    # Filter names based on conditions\n",
    "    filtered_names = [name for name in string_database if all(part in name.lower() for part in parts)]\n",
    "    \n",
    "    return filtered_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_names_with_conditions(df):\n",
    "    # Create an empty list to store names that satisfy the conditions\n",
    "    result_names = []\n",
    "\n",
    "    # Iterate through unique names in the DataFrame\n",
    "    for name in df['Name'].unique():\n",
    "        # Create a subset of the DataFrame for the current name\n",
    "        subset = df[df['Name'] == name].reset_index()\n",
    "\n",
    "        # Check conditions: length of subset is 1 and 'Market Value' is equal to '-'\n",
    "        if len(subset) == 1 and subset['Market Value'].iloc[0] == '-':\n",
    "            result_names.append(name)\n",
    "\n",
    "    return result_names\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'csv_leagues.csv' is your CSV file or provide the DataFrame directly\n",
    "# csv_leagues = pd.read_csv('csv_leagues.csv')\n",
    "result_names_null = get_names_with_conditions(csv_leagues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING / WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertrand Traoré\n",
      "Bertrand Traoré is in dataset for 2016 in 2016\n",
      "value in 07.10.16 is 8000000.0\n"
     ]
    }
   ],
   "source": [
    "#Draft 2 - Moving step by step\n",
    "\n",
    "# example_problem = \"17. N'Diaye M.\"\n",
    "# natl_test = 'Mali'\n",
    "# input_year_test = '17.01.17'\n",
    "\n",
    "\n",
    "example_problem = '19 B. Traoré'\n",
    "natl_test = 'Burkina Faso'\n",
    "input_year_test = \"07.10.16\"\n",
    "\n",
    "\n",
    "candidate_name = \"\"\n",
    "\n",
    "#players from their country \n",
    "dataset_nationality = csv_leagues[csv_leagues['Nationality'] == f\"{natl_test}\"]['Name'].unique()\n",
    "\n",
    "if(is_cyrillic(example_problem)):\n",
    "    #change from cyrillic to english\n",
    "    example_problem = cyrillic_to_latin(example_problem)\n",
    "\n",
    "#remove jersey Nums and order initials correctly. \n",
    "search_name, final_tokens_name = process_string_newest_ii(example_problem) \n",
    "\n",
    "#look their name up in the list of names from their nationality. \n",
    "# result = find_closest_string(search_name, dataset_nationality)\n",
    "result = find_closest_string_newEST(search_name, dataset_nationality, final_tokens_name, example_problem)\n",
    "if(result in dataset_nationality):\n",
    "    print(result)\n",
    "    #RETURN \n",
    "    candidate_name = result\n",
    "else:\n",
    "    #no match found after first call \n",
    "    print('no initial match found: ', search_name)\n",
    "    nationality_names_accents_removed = remove_accents_from_strings(dataset_nationality)\n",
    "    match_accent_accounted = find_closest_string_newEST(search_name, nationality_names_accents_removed,final_tokens_name, example_problem)\n",
    "    if(match_accent_accounted in nationality_names_accents_removed):\n",
    "        #print(match_accent_accounted)\n",
    "        matching_names_with_accents = find_names_with_accents(match_accent_accounted, dataset_nationality)\n",
    "        if(type(matching_names_with_accents) == str):\n",
    "            print(matching_names_with_accents)\n",
    "            #RETURN\n",
    "            candidate_name = matching_names_with_accents\n",
    "        elif(len(matching_names_with_accents) == 0):\n",
    "            print(f'accent-less name found: {match_accent_accounted}. But name not in original dataset')\n",
    "        else:\n",
    "            print(f'multiple names found after adding accents: {matching_names_with_accents}')\n",
    "\n",
    "\n",
    "        #MAKE SURE THE NAME WITH ACCENTS IS IN DATASET NATIONALITY \n",
    "    else:\n",
    "        print('no accent match found: ', search_name)\n",
    "\n",
    "        dataset_nationality_backticks = remove_apostrophes_backticks(dataset_nationality) #dataset_nationality_updated\n",
    "        match_apostrophes_accounted = find_closest_string_newEST(search_name, dataset_nationality_backticks,final_tokens_name, example_problem)\n",
    "    \n",
    "        if(match_apostrophes_accounted in dataset_nationality_backticks):\n",
    "            #print(match_apostrophes_accounted)\n",
    "\n",
    "            lastname_match = match_apostrophes_accounted.split()[-1] \n",
    "            original_string_nojersey = re.sub(r'^\\d+(\\.)?\\s*', '', example_problem)\n",
    "            correct_lastname = add_backticks(lastname_match, original_string_nojersey)\n",
    "            correct_firstname = extract_first_name(match_apostrophes_accounted, lastname_match)\n",
    "            \n",
    "            correct_name_full = correct_firstname + ' ' + correct_lastname\n",
    "\n",
    "            if(correct_name_full in dataset_nationality):\n",
    "                print(correct_name_full)\n",
    "                #RETURN\n",
    "                candidate_name = correct_name_full\n",
    "            elif(correct_name_full.replace('`', \"'\") in dataset_nationality):\n",
    "                print(correct_name_full.replace('`', \"'\"))\n",
    "                #RETURN\n",
    "                candidate_name = correct_name_full.replace('`', \"'\")\n",
    "            else:\n",
    "                print(f'backtick-less name found: {match_apostrophes_accounted}. But name not in original dataset')\n",
    "           \n",
    "        else:\n",
    "            print('no backtick match found: ', search_name)\n",
    "\n",
    "if(candidate_name != \"\"):\n",
    "    #There's a match\n",
    "\n",
    "\n",
    "    ###CHECK AGAINST NULL LIST\n",
    "\n",
    "    yearstr = input_year_test.split(\".\")[2]\n",
    "    full_num = '20' + yearstr\n",
    "\n",
    "    that_season_that_guy = csv_leagues[(csv_leagues['Name'] == candidate_name) & (csv_leagues['Season'] == int(full_num))]\n",
    "\n",
    "    #NO DATA FOR YEAR OF THE MATCH\n",
    "    if(len(that_season_that_guy) == 0):\n",
    "\n",
    "        prev_season_that_guy = csv_leagues[(csv_leagues['Name'] == candidate_name) & (csv_leagues['Season'] == (int(full_num) + 1))]\n",
    "        next_season_that_guy = csv_leagues[(csv_leagues['Name'] == candidate_name) & (csv_leagues['Season'] == (int(full_num) - 1))]\n",
    "        thatguy_3seasons = pd.concat([that_season_that_guy, prev_season_that_guy, next_season_that_guy], ignore_index=True)\n",
    "        \n",
    "        #NO DATA FOR YEAR BEFORE OR AFTER THE MATCH\n",
    "        if(len(thatguy_3seasons) == 0):\n",
    "            print(f'{candidate_name} wasn\\'t in the db in {full_num}, {int(full_num) + 1} or {int(full_num) - 1} ')\n",
    "            ###AAA\n",
    "        \n",
    "        #SOME DATA FOR YEAR BEFORE OR AFTER THE MATCH\n",
    "        else:\n",
    "            0==0\n",
    "            print(f'{candidate_name} was in the db in {full_num}, but was in {int(full_num) + 1} or {int(full_num) - 1} ')\n",
    "            \n",
    "    \n",
    "    #SOME DATA FOR YEAR OF THE MATCH\n",
    "    else:\n",
    "        print(f\"{candidate_name} is in dataset for {int(full_num)} in {full_num}\")\n",
    "\n",
    "        ###CHECK AGAINST NULL LIST\n",
    "\n",
    "        array_with_nan = that_season_that_guy['Market Value'].unique()\n",
    "\n",
    "        # Convert the values to numeric, treating 'nan' as NaN\n",
    "        numeric_values = pd.to_numeric(array_with_nan, errors='coerce')\n",
    "        # Find the maximum value excluding NaNs\n",
    "\n",
    "        ###$$$\n",
    "        if np.isnan(numeric_values).all():\n",
    "            print(\"Test case: All-NaN slice encountered\")\n",
    "            #USING THEIR OWN SALARIES \n",
    "            # prev_season_that_guy = csv_leagues[(csv_leagues['Name'] == candidate_name) & (csv_leagues['Season'] == (int(full_num) + 1))]\n",
    "            # next_season_that_guy = csv_leagues[(csv_leagues['Name'] == candidate_name) & (csv_leagues['Season'] == (int(full_num) - 1))]\n",
    "            # thatguy_3seasons = pd.concat([that_season_that_guy, prev_season_that_guy, next_season_that_guy], ignore_index=True)\n",
    "            # szn_array_with_nan = thatguy_3seasons['Yearly Salary'].unique()\n",
    "            # numeric_values_3szn = pd.to_numeric(szn_array_with_nan, errors='coerce')\n",
    "            \n",
    "            #USING LEAGUE AVG SALARIES\n",
    "            # league = that_season_that_guy.reset_index().at[0, 'League']\n",
    "            # season = that_season_that_guy.reset_index().at[0, 'Season']\n",
    "\n",
    "\n",
    "            # mean_salary = pd.to_numeric(csv_leagues[(csv_leagues['League'] == league) & (csv_leagues['Season'] == season)]['Inflation-Adjusted Yearly Salary'], errors='coerce').mean()\n",
    "            # mediansalary = csv_leagues[(csv_leagues['League'] == league) & (csv_leagues['Season'] == season)]['Inflation-Adjusted Yearly Salary'].median()\n",
    "            # print(mean_salary, mediansalary)\n",
    "\n",
    "        else:\n",
    "            # Find the maximum value excluding NaNs\n",
    "            max_value_excluding_nan = np.nanmax(numeric_values)\n",
    "            print(f\"value in {input_year_test} is {max_value_excluding_nan}\")\n",
    "\n",
    "else:\n",
    "    #No matches after 3 tries \n",
    "    result = filter_names_first_initial_lastname(csv_leagues['Name'].unique(), search_name)\n",
    "    list_left = filter_candidates(search_name, result)\n",
    "\n",
    "    natl_list = []\n",
    "    for i in range(0, len(list_left)):\n",
    "        if(natl_test in csv_leagues[csv_leagues['Name'] == list_left[i]]['Nationality'].unique()):\n",
    "            natl_list.append(list_left[i])\n",
    "\n",
    "    if(len(natl_list) == 1):\n",
    "        0==0\n",
    "        #one match remaining. \n",
    "        #RETURN\n",
    "        print(f'after filtering 4th time found {natl_list[0]}')\n",
    "\n",
    "    elif(len(natl_list) == 2):\n",
    "        #still not quite matched up\n",
    "        #print something. probably should search this guy \n",
    "        0==0\n",
    "    else:\n",
    "        ###BBB\n",
    "        0==0\n",
    "        print('no match after 4')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
