{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from countries_languages import country_to_language\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "import numpy as np\n",
    "import re\n",
    "from transliterate import translit\n",
    "from unidecode import unidecode\n",
    "import Levenshtein\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import wikipediaapi\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import difflib\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import calendar\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import AssemblyHelpers\n",
    "#from AssemblyHelpers import find_money_info_from_name\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def load_csv_dataset(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "countries_codes = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/countries_and_codes.csv')\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def find_close_matches_variable(this_jersey, dataset_nationality, threshold):\n",
    "    \"\"\"\n",
    "    Find close matches of `this_jersey` in `dataset_nationality` using Levenshtein distance.\n",
    "\n",
    "    Args:\n",
    "    - this_jersey (str): The string to find close matches for.\n",
    "    - dataset_nationality (list): List of strings to search for close matches in.\n",
    "    - threshold (int): Minimum similarity score required for a match (default is 90).\n",
    "\n",
    "    Returns:\n",
    "    - List of strings from `dataset_nationality` that are close matches to `this_jersey`.\n",
    "    \"\"\"\n",
    "    close_matches = process.extract(this_jersey, dataset_nationality, limit=None)\n",
    "    return [match[0] for match in close_matches if match[1] >= threshold]\n",
    "\n",
    "#threshold match one \n",
    "def threshold_player_match(this_jersey, dataset_nationality):\n",
    "    THRESHOLD_NUM = 89\n",
    "    #stops when it returns a name.\n",
    "    #if it doesnt find a match keep lowering the threshold until you find a match\n",
    "    #but if you get to threshold of like 50 first you stop and just abandon ship    \n",
    "\n",
    "    # Loop until someone is found or threshold goes below 50\n",
    "    while THRESHOLD_NUM >= 50:\n",
    "        matches = find_close_matches_variable(this_jersey, dataset_nationality, THRESHOLD_NUM)\n",
    "        if matches:\n",
    "            #print(f\"Player is {this_jersey}. Found matches: {matches}. threshold is {THRESHOLD_NUM}\")\n",
    "            return matches, THRESHOLD_NUM\n",
    "            #break\n",
    "        else:\n",
    "            THRESHOLD_NUM -= 1\n",
    "\n",
    "    # If threshold reaches below 50 without finding any matches\n",
    "    if THRESHOLD_NUM < 50:\n",
    "        return [f\"No matches found even with the lowest threshold.\"], this_jersey #jersey was {this_jersey}\n",
    "\n",
    "\n",
    "def filter_using_date_of_match(candidate_list_of_names_input, nationality_input, matchdate_Input, SALARY_BOOLEAN): \n",
    "\n",
    "    FILTERED_NAMES_USING_MATCH_DATE = AssemblyHelpers.multiNameMatchDateLookup(candidate_list_of_names_input, nationality_input, matchdate_Input) \n",
    "\n",
    "    #print('in fudom', type(FILTERED_NAMES_USING_MATCH_DATE))\n",
    "    #1 MATCH\n",
    "    if isinstance(FILTERED_NAMES_USING_MATCH_DATE, str) or isinstance(FILTERED_NAMES_USING_MATCH_DATE, np.str_): #YELLOW 3\n",
    "        #print('were here', FILTERED_NAMES_USING_MATCH_DATE)\n",
    "        #print('were in fudom in the right place')\n",
    "        #NAME_FOR_SELENIUM_SEARCH = FILTERED_NAMES_USING_MATCH_DATE\n",
    "        # MONEY_FOUND_ONLINE = useSeleniumToFindMoney(NAME_FOR_SELENIUM_SEARCH, nationality_input, matchdate_Input, SALARY_BOOLEAN)\n",
    "        # print('made it out of using selenium')\n",
    "        # money_thisplayer = [MONEY_FOUND_ONLINE, f'Online WAS Lookup Required - salary boolean is {SALARY_BOOLEAN}', True, False]\n",
    "        money_thisplayer = [0, 'Lookup Required', True, False]\n",
    "        return money_thisplayer, FILTERED_NAMES_USING_MATCH_DATE\n",
    "    #MULTIPLE MATCHES\n",
    "    elif(len(FILTERED_NAMES_USING_MATCH_DATE) >= 2):\n",
    "        print(FILTERED_NAMES_USING_MATCH_DATE, type(FILTERED_NAMES_USING_MATCH_DATE), type(FILTERED_NAMES_USING_MATCH_DATE) == str)\n",
    "        money_thisplayer = [0, F'FILTERING USING MATCH DATE LEFT MULTIPLE RESULTS: {FILTERED_NAMES_USING_MATCH_DATE}', True, False]\n",
    "        return money_thisplayer, FILTERED_NAMES_USING_MATCH_DATE\n",
    "    #0 MATCHES\n",
    "    elif(len(FILTERED_NAMES_USING_MATCH_DATE) == 0):\n",
    "        money_thisplayer = [0, F'FILTERING USING MATCH DATE LEFT 0 RESULTS. BEFORE FILTERING, CANDIDATE NAMES WERE {candidate_list_of_names_input}', True, False]\n",
    "        return money_thisplayer, ''\n",
    "    \n",
    "\n",
    "def check_tokens(this_jersey, match):\n",
    "    jersey_tokens = this_jersey.lower().split()\n",
    "    match_tokens = match.lower().split()\n",
    "    \n",
    "    if all(token in match_tokens for token in jersey_tokens):\n",
    "        return True\n",
    "    elif all(token in jersey_tokens for token in match_tokens) and len(jersey_tokens) == len(match_tokens) + 1:\n",
    "        return True\n",
    "    elif all(token in match_tokens for token in jersey_tokens) and len(jersey_tokens) > len(match_tokens):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def filter_multi_word_matches_by_jersey_tokens(jersey_tokens, potential_matches):\n",
    "    filtered_matches = []\n",
    "\n",
    "    for match in potential_matches:\n",
    "        # Split each match into tokens\n",
    "        match_tokens = match.split()\n",
    "\n",
    "        # Count the number of tokens that start with each character in jersey_tokens\n",
    "        match_token_start_chars = {token[0] for token in match_tokens}\n",
    "        #print(match_token_start_chars, f\"*{jersey_tokens}\")\n",
    "\n",
    "        #for token in jersey_tokens:\n",
    "        #   print(token, token[0] in match_token_start_chars)\n",
    "\n",
    "        # Check if the match contains at least one token for each character in jersey_tokens\n",
    "        if all(token[0] in match_token_start_chars for token in jersey_tokens):\n",
    "            filtered_matches.append(match)\n",
    "\n",
    "    return filtered_matches\n",
    "\n",
    "def in_season_around(player_id, curr_season, age):\n",
    "    if age == \"Not Listed\": age = 30\n",
    "    age = int(age)\n",
    "    year_before = int(curr_season) -1\n",
    "    year_after = int(curr_season) + 1\n",
    "    before_season = transfermarkt_data[(transfermarkt_data['PlayerID'] == player_id) & (transfermarkt_data['Season'] == year_before)]\n",
    "    after_season =  transfermarkt_data[(transfermarkt_data['PlayerID'] == player_id) & (transfermarkt_data['Season'] == year_after)]\n",
    "    if before_season.empty and after_season.empty:\n",
    "        return -1, \"Both Empty\"\n",
    "    if not before_season.empty and after_season.empty:\n",
    "        if before_season.iloc[0]['Market Value'] != \"-\":\n",
    "            if before_season.iloc[0]['Market Value'] == 0:\n",
    "                return 0, \"Only Before + Zero Before\"\n",
    "            else:\n",
    "                if age >= 30:\n",
    "                    return (float(before_season.iloc[0]['Market Value']) * .8), \"Only Before\"\n",
    "                else:\n",
    "                    return (float(before_season.iloc[0]['Market Value']) * 1.2), \"Only Before\"\n",
    "        else:\n",
    "            return 0, \"Only Before X\"\n",
    "    if not after_season.empty and before_season.empty:\n",
    "        \n",
    "        if after_season.iloc[0]['Market Value'] != \"-\":\n",
    "            if after_season.iloc[0]['Market Value'] == 0:\n",
    "                return 0, \"Only After + Zero After\"\n",
    "            else:\n",
    "                if age <= 30:\n",
    "                    return (float(after_season.iloc[0]['Market Value']) * .8), \"Only After\"\n",
    "                else:\n",
    "                    return (float(after_season.iloc[0]['Market Value']) * 1.2), \"Only After\"\n",
    "        else:\n",
    "            return 0, \"Only After X\"\n",
    "    if not before_season.empty and not after_season.empty:\n",
    "        before_season_val = before_season.iloc[0]['Market Value']\n",
    "        after_season_val = after_season.iloc[0]['Market Value']\n",
    "        if before_season_val != \"-\" and after_season_val != \"-\":\n",
    "            return ((float(before_season.iloc[0]['Market Value']) + float(after_season.iloc[0]['Market Value'])) / 2), \"Used Average of Season Before and After\"\n",
    "        elif before_season_val != \"-\" and after_season_val == \"-\":\n",
    "            if age >= 30:\n",
    "                return (float(before_season.iloc[0]['Market Value']) * .8), \"Used Season Before * .8 But Had Both\"\n",
    "            else:\n",
    "                return (float(before_season.iloc[0]['Market Value']) * 1.2), \"Used Season Before * 1.2 But Had Both\"\n",
    "        elif before_season_val == \"-\" and after_season_val != \"-\":\n",
    "            if age <= 30:\n",
    "                return (float(after_season.iloc[0]['Market Value']) * .8), \"Used Season After * .8 But Had Both\"\n",
    "            else:\n",
    "                return (float(after_season.iloc[0]['Market Value']) * 1.2), \"Used Season After * 1.2 But Had Both\"\n",
    "        else:\n",
    "            return 0, \"Had Both but Both Were Empty\"\n",
    "\n",
    "def find_in_transfermarkt(player_name, season, country_code, transfermarkt_data):\n",
    "    row = transfermarkt_data[(transfermarkt_data['Name'] == player_name) & (transfermarkt_data['Season'] == season) & (transfermarkt_data['Team 1 Code'] == country_code)]\n",
    "    one_up_row = transfermarkt_data[(transfermarkt_data['Name'] == player_name) & (transfermarkt_data['Season'] == int(season)+1) & (transfermarkt_data['Team 1 Code'] == country_code)]\n",
    "    one_down_row = transfermarkt_data[(transfermarkt_data['Name'] == player_name) & (transfermarkt_data['Season'] == int(season)-1) & (transfermarkt_data['Team 1 Code'] == country_code)]\n",
    "    if not row.empty:\n",
    "        player_id = row.iloc[0]['PlayerID']\n",
    "        age = row.iloc[0]['Age']\n",
    "        marketval = row.iloc[0]['Market Value']\n",
    "        if marketval != 0:\n",
    "            return marketval, \"Found in Curr Season\"\n",
    "        else:\n",
    "            new_mv, reason = in_season_around(player_id, season, age)\n",
    "            if new_mv == -1 or new_mv == 0 or new_mv == \"-\":\n",
    "                return 0, reason\n",
    "            else:\n",
    "                return new_mv, reason\n",
    "    elif not one_up_row.empty:\n",
    "        player_id = one_up_row.iloc[0]['PlayerID']\n",
    "        age = one_up_row.iloc[0]['Age']\n",
    "        new_mv, reason = in_season_around(player_id, season, age)\n",
    "        if new_mv == -1 or new_mv == 0 or new_mv == \"-\":\n",
    "            return 0, reason\n",
    "        else:\n",
    "            return new_mv, reason\n",
    "    elif not one_down_row.empty:\n",
    "        player_id = one_down_row.iloc[0]['PlayerID']\n",
    "        age = one_down_row.iloc[0]['Age']\n",
    "        new_mv, reason = in_season_around(player_id, season, age)\n",
    "        if new_mv == -1 or new_mv == 0 or new_mv == \"-\":\n",
    "            return 0, reason\n",
    "        else:\n",
    "            return new_mv, reason\n",
    "    else:\n",
    "        return 0, \"Did Not Find in Curr Season, One Up, or One Down\"\n",
    "\n",
    "def check_other_team(lookup_row, transfermarkt_data, results_df):\n",
    "    new_rows = []\n",
    "    wrong_rows = []\n",
    "\n",
    "    name = lookup_row['Name']\n",
    "    original_jersey = lookup_row['ORIGINAL JERSEY']\n",
    "    season = lookup_row['Season']\n",
    "    original_country_code = lookup_row['Team Country Code']\n",
    "    match_id = lookup_row['Match ID']\n",
    "    opposing_country_code = \"\"\n",
    "    game_row = results_df[results_df['Match ID'] == match_id]\n",
    "    \n",
    "    if len(game_row) != 1:\n",
    "        raise ValueError(\"There should only be one match per ID\")\n",
    "\n",
    "    team2_code = game_row.iloc[0]['Team 2 Code']\n",
    "    team1_code = game_row.iloc[0]['Team 1 Code']\n",
    "\n",
    "    if original_country_code == team1_code:\n",
    "        opposing_country_code = team2_code\n",
    "    elif original_country_code == team2_code:\n",
    "        opposing_country_code = team1_code\n",
    "    else:\n",
    "        raise ValueError(\"Original country code does not match any team in the match\")\n",
    "\n",
    "    dataset_nationality = transfermarkt_data[transfermarkt_data['Team 1 Code'] == opposing_country_code]['Name'].unique()\n",
    "    possible_names = threshold_player_match(original_jersey, dataset_nationality)\n",
    "    # found_name = False\n",
    "    # for i in range(len(possible_names[0])):\n",
    "    #     if possible_names[0][i] == name:\n",
    "    #         new_mv, valid_zero = find_in_transfermarkt(name, season, opposing_country_code, transfermarkt_data)\n",
    "    #         new_row = game_row.to_dict()  # Convert row to dict\n",
    "    #         new_row['Market Value'] = new_mv\n",
    "    #         new_row['Lookup Still Required?'] = \"FALSE\"\n",
    "    #         new_row['Lookup Return Case'] = valid_zero\n",
    "    #         new_rows.append(new_row)\n",
    "    #         found_name = True\n",
    "    #         break\n",
    "    # if not found_name:\n",
    "    #     new_row = game_row.to_dict()\n",
    "    #     new_row['Wrong Name'] = \"Yes\"\n",
    "    #     new_row['Found Name'] = possible_names[0]\n",
    "    #     wrong_rows.append(new_row)\n",
    "    # new_df = pd.DataFrame(new_rows)\n",
    "    # wrong_df = pd.DataFrame(wrong_rows)\n",
    "    # return new_df, wrong_df\n",
    "    return possible_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/z2xv57_n70l_szw_fr80j5km0000gn/T/ipykernel_53856/251060467.py:49: DtypeWarning: Columns (4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "#leagues value\n",
    "#leagues_value = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/Most Updated Edited Transfermarkt Dataset.csv')\n",
    "transfermarkt_data = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/MarketValuesComplete.csv')\n",
    "\n",
    "#leagues value large \n",
    "leagues_value_large = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/most_updated_transfermarkt_dataset.csv')\n",
    "\n",
    "results_df = load_csv_dataset('newest_results_data_march_24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/z2xv57_n70l_szw_fr80j5km0000gn/T/ipykernel_53856/1888214061.py:49: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lookup Return Case\n",
       "Only Before                                         4255\n",
       "Used Average of Season Before and After             2765\n",
       "Had Both but Both Were Empty                        2221\n",
       "Used Season After * .8 But Had Both                 1057\n",
       "Only After                                          1035\n",
       "Only Before + Zero Before                            408\n",
       "Both Empty                                           339\n",
       "Only After + Zero After                              169\n",
       "Used Season Before * 1.2                             163\n",
       "Did Not Find in Curr Season, One Up, or One Down     115\n",
       "Used Season Before * 1.2 But Had Both                 84\n",
       "Used Season After * 1.2 But Had Both                  80\n",
       "Used Season Before * .8                               31\n",
       "Used Season Before * .8 But Had Both                  14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_combined_df = load_csv_dataset('combined_DF_merged_April_24.csv')\n",
    "large_combined_df = large_combined_df.drop(columns={'Unnamed: 0'})\n",
    "\n",
    "#filter large combined DF \n",
    "large_combined_df_working = large_combined_df[(large_combined_df['Lookup Return Case'] == 'working') | \n",
    "                                              (large_combined_df['Lookup Return Case'] == 'Found in Curr Season') | \n",
    "                                              (large_combined_df['Lookup Return Case'] == 'Used Large Dataset')]\n",
    "\n",
    "large_combined_df_not_working = large_combined_df[(large_combined_df['Lookup Return Case'] != 'working') &\n",
    "                                              (large_combined_df['Lookup Return Case'] != 'Found in Curr Season') &\n",
    "                                              (large_combined_df['Lookup Return Case'] != 'Used Large Dataset')].reset_index()\n",
    "\n",
    "large_combined_df_not_working['Lookup Return Case'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check other team \n",
    "\n",
    "    #DONE - need the row \n",
    "\n",
    "    #DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_name_match(name, dataset_of_names):\n",
    "    matching_names = []\n",
    "    for full_name in dataset_of_names:\n",
    "        \n",
    "        # Split the full name into tokens\n",
    "        full_name_tokens = set(re.split(r'\\s+|[-–]', full_name))\n",
    "        \n",
    "        # Check if any token matches the last name or its unidecoded version\n",
    "        for token in full_name_tokens:\n",
    "            #if full_name == 'Fródi Benjaminsen':\n",
    "                #print(token, name, token == name)\n",
    "                #print(full_name_tokens)\n",
    "            \n",
    "            if token == name or unidecode(token) == name:\n",
    "                matching_names.append(full_name)\n",
    "                break  # Once a match is found, move to the next name\n",
    "    return matching_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 other country match didnt work\n",
      "0 single return Fródi Benjaminsen\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "find_in_transfermarkt() missing 3 required positional arguments: 'season', 'country_code', and 'transfermarkt_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     correct_name \u001b[38;5;241m=\u001b[39m names_same_nation_last_name[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle return\u001b[39m\u001b[38;5;124m'\u001b[39m, names_same_nation_last_name[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 25\u001b[0m     number, reason \u001b[38;5;241m=\u001b[39m \u001b[43mfind_in_transfermarkt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransfermarkt_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNobody with this last name WITH CURRENT from the nation\u001b[39m\u001b[38;5;124m'\u001b[39m, names_same_nation_last_name, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIGINAL JERSEY\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: find_in_transfermarkt() missing 3 required positional arguments: 'season', 'country_code', and 'transfermarkt_data'"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1): #len(large_combined_df_not_working)\n",
    "    row = large_combined_df_not_working.loc[i]\n",
    "    jersey = row['ORIGINAL JERSEY']\n",
    "    names_found = row['Name(s) Found']\n",
    "    test = check_other_team(row, transfermarkt_data, results_df)\n",
    "    if test == ['No matches found even with the lowest threshold.']:\n",
    "        print(i, 'other country match didnt work')\n",
    "        last_name = re.split(r'\\s+|[-–]', jersey)[-1]\n",
    "        this_country_code = row['Team Country Code']\n",
    "        dataset_nationality = transfermarkt_data[transfermarkt_data['Team 1 Code'] == this_country_code]['Name'].unique()\n",
    "        names_same_nation_last_name = last_name_match(last_name, dataset_nationality)\n",
    "        if names_same_nation_last_name == None:\n",
    "            print(i, 'last name match returned nobody')\n",
    "        else:\n",
    "            correct_season = row['Season']\n",
    "            for name_candidate in names_same_nation_last_name:\n",
    "                num_seasons_around = len(transfermarkt_data[(transfermarkt_data['Name'] == name_candidate) & (transfermarkt_data['Season'].isin([correct_season, correct_season + 1, correct_season - 1]))])\n",
    "                if num_seasons_around == 0:\n",
    "                    names_same_nation_last_name.remove(name_candidate)\n",
    "            if len(names_same_nation_last_name) >= 2:\n",
    "                print(i, 'match date filter required here', names_same_nation_last_name)\n",
    "            elif len(names_same_nation_last_name) == 1:\n",
    "                correct_name = names_same_nation_last_name[0]\n",
    "                print(i, 'single return', names_same_nation_last_name[0])\n",
    "                number, reason = find_in_transfermarkt(transfermarkt_data)\n",
    "            else:\n",
    "                print(i, 'Nobody with this last name WITH CURRENT from the nation', names_same_nation_last_name, row['ORIGINAL JERSEY'])\n",
    "                #try using leagues_value_large here\n",
    "                dataset_nationality_large = leagues_value_large[leagues_value_large['Team 1 Code'] == this_country_code]['Name'].unique()\n",
    "                names_same_nation_last_name_large_dataset = last_name_match(last_name, dataset_nationality_large)    \n",
    "                if names_same_nation_last_name == None:\n",
    "                    print(i, 'last name match using large dataset ALSO returned nobody')\n",
    "    else:\n",
    "        print(i, 'other nation yielded ', test)\n",
    "\n",
    "    #MAKE SURE ITS A BAD EDGE CASES\n",
    "\n",
    "    #thing 1 to try\n",
    "\n",
    "    #thing 2\n",
    "\n",
    "    #thing 3 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
