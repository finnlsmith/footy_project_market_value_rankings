{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from countries_languages import country_to_language\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "import numpy as np\n",
    "import re\n",
    "from transliterate import translit\n",
    "from unidecode import unidecode\n",
    "import Levenshtein\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import wikipediaapi\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import difflib\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import calendar\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import AssemblyHelpers\n",
    "#from AssemblyHelpers import find_money_info_from_name\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def load_csv_dataset(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "countries_codes = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/countries_and_codes.csv')\n",
    "\n",
    "#leagues value\n",
    "leagues_value = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/Most Updated Edited Transfermarkt Dataset.csv')\n",
    "#leagues value large \n",
    "leagues_value_large = load_csv_dataset('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/most_updated_transfermarkt_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIG DATASET\n",
    "\n",
    "large_df_combined = load_csv_dataset('updated COMBINED DF_WORKING.csv')\n",
    "\n",
    "\n",
    "terrell_new_df = load_csv_dataset('CSVs of edge cases - for T/updated Terrell new DF.csv')\n",
    "len(terrell_new_df), len(large_df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group 1 \n",
    "\n",
    "group_1_updated = load_csv_dataset('updated_Group1_fixes_complete_ii.csv')\n",
    "len(group_1_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group 2 \n",
    "\n",
    "online_lookup_group_2 = load_csv_dataset('Group 2 (for T) - Find their $ Info/Online lookup required - 1 name found.csv')\n",
    "\n",
    "lookup_group_2 = load_csv_dataset('Group 2 (for T) - Find their $ Info/lookup_required_matches.csv')\n",
    "\n",
    "cyrillic_group_2 = load_csv_dataset('Group 2 (for T) - Find their $ Info/Cyrillic_Found_Guys.csv')\n",
    "len(online_lookup_group_2), len(lookup_group_2), len(cyrillic_group_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group 3 \n",
    "\n",
    "cyrillic_group_3 = load_csv_dataset('CSVs of edge cases - for F/Group 3 - Nobody Found/Cyrillic_Guys_Nobody_Found.csv')\n",
    "\n",
    "zeros_group_3 = load_csv_dataset('CSVs of edge cases - for F/Group 3 - Nobody Found/odd_name_found_0_cases.csv')\n",
    "\n",
    "online_lookup_group_3 = load_csv_dataset('CSVs of edge cases - for F/Group 3 - Nobody Found/Online lookup required - 0 names found.csv')\n",
    "\n",
    "len(cyrillic_group_3), len(zeros_group_3), len(online_lookup_group_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other group\n",
    "\n",
    "wrong_df = load_csv_dataset('CSVs of edge cases - for F/\"other\" group/updated Terrell lookup cases - wrong DF.csv')\n",
    "wrong_df = wrong_df.drop(columns={'Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.2'})\n",
    "lookup_required_dudes = load_csv_dataset('CSVs of edge cases - for F/\"other\" group/lookup_required_dudes.csv')\n",
    "\n",
    "large_dataset_said_0 = load_csv_dataset('CSVs of edge cases - for F/\"other\" group/updated_large_dataset_said_0.csv')\n",
    "\n",
    "match_date_filter_said_0_guys = load_csv_dataset('CSVs of edge cases - for F/\"other\" group/updated match date said zero guys.csv')\n",
    "\n",
    "len(wrong_df), len(lookup_required_dudes), len(large_dataset_said_0), len(match_date_filter_said_0_guys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORKING WITH WRONG DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "def find_close_matches_variable(this_jersey, dataset_nationality, threshold):\n",
    "    \"\"\"\n",
    "    Find close matches of `this_jersey` in `dataset_nationality` using Levenshtein distance.\n",
    "\n",
    "    Args:\n",
    "    - this_jersey (str): The string to find close matches for.\n",
    "    - dataset_nationality (list): List of strings to search for close matches in.\n",
    "    - threshold (int): Minimum similarity score required for a match (default is 90).\n",
    "\n",
    "    Returns:\n",
    "    - List of strings from `dataset_nationality` that are close matches to `this_jersey`.\n",
    "    \"\"\"\n",
    "    close_matches = process.extract(this_jersey, dataset_nationality, limit=None)\n",
    "    return [match[0] for match in close_matches if match[1] >= threshold]\n",
    "\n",
    "#threshold match one \n",
    "def threshold_player_match(this_jersey, dataset_nationality):\n",
    "    THRESHOLD_NUM = 89\n",
    "    #stops when it returns a name.\n",
    "    #if it doesnt find a match keep lowering the threshold until you find a match\n",
    "    #but if you get to threshold of like 50 first you stop and just abandon ship    \n",
    "\n",
    "    # Loop until someone is found or threshold goes below 50\n",
    "    while THRESHOLD_NUM >= 50:\n",
    "        matches = find_close_matches_variable(this_jersey, dataset_nationality, THRESHOLD_NUM)\n",
    "        if matches:\n",
    "            #print(f\"Player is {this_jersey}. Found matches: {matches}. threshold is {THRESHOLD_NUM}\")\n",
    "            return matches, THRESHOLD_NUM\n",
    "            #break\n",
    "        else:\n",
    "            THRESHOLD_NUM -= 1\n",
    "\n",
    "    # If threshold reaches below 50 without finding any matches\n",
    "    if THRESHOLD_NUM < 50:\n",
    "        return [f\"No matches found even with the lowest threshold.\"], this_jersey #jersey was {this_jersey}\n",
    "\n",
    "\n",
    "def filter_using_date_of_match(candidate_list_of_names_input, nationality_input, matchdate_Input, SALARY_BOOLEAN): \n",
    "\n",
    "    FILTERED_NAMES_USING_MATCH_DATE = AssemblyHelpers.multiNameMatchDateLookup(candidate_list_of_names_input, nationality_input, matchdate_Input) \n",
    "\n",
    "    #print('in fudom', type(FILTERED_NAMES_USING_MATCH_DATE))\n",
    "    #1 MATCH\n",
    "    if isinstance(FILTERED_NAMES_USING_MATCH_DATE, str) or isinstance(FILTERED_NAMES_USING_MATCH_DATE, np.str_): #YELLOW 3\n",
    "        #print('were here', FILTERED_NAMES_USING_MATCH_DATE)\n",
    "        #print('were in fudom in the right place')\n",
    "        #NAME_FOR_SELENIUM_SEARCH = FILTERED_NAMES_USING_MATCH_DATE\n",
    "        # MONEY_FOUND_ONLINE = useSeleniumToFindMoney(NAME_FOR_SELENIUM_SEARCH, nationality_input, matchdate_Input, SALARY_BOOLEAN)\n",
    "        # print('made it out of using selenium')\n",
    "        # money_thisplayer = [MONEY_FOUND_ONLINE, f'Online WAS Lookup Required - salary boolean is {SALARY_BOOLEAN}', True, False]\n",
    "        money_thisplayer = [0, 'Lookup Required', True, False]\n",
    "        return money_thisplayer, FILTERED_NAMES_USING_MATCH_DATE\n",
    "    #MULTIPLE MATCHES\n",
    "    elif(len(FILTERED_NAMES_USING_MATCH_DATE) >= 2):\n",
    "        print(FILTERED_NAMES_USING_MATCH_DATE, type(FILTERED_NAMES_USING_MATCH_DATE), type(FILTERED_NAMES_USING_MATCH_DATE) == str)\n",
    "        money_thisplayer = [0, F'FILTERING USING MATCH DATE LEFT MULTIPLE RESULTS: {FILTERED_NAMES_USING_MATCH_DATE}', True, False]\n",
    "        return money_thisplayer, FILTERED_NAMES_USING_MATCH_DATE\n",
    "    #0 MATCHES\n",
    "    elif(len(FILTERED_NAMES_USING_MATCH_DATE) == 0):\n",
    "        money_thisplayer = [0, F'FILTERING USING MATCH DATE LEFT 0 RESULTS. BEFORE FILTERING, CANDIDATE NAMES WERE {candidate_list_of_names_input}', True, False]\n",
    "        return money_thisplayer, ''\n",
    "    \n",
    "\n",
    "def check_tokens(this_jersey, match):\n",
    "    jersey_tokens = this_jersey.lower().split()\n",
    "    match_tokens = match.lower().split()\n",
    "    \n",
    "    if all(token in match_tokens for token in jersey_tokens):\n",
    "        return True\n",
    "    elif all(token in jersey_tokens for token in match_tokens) and len(jersey_tokens) == len(match_tokens) + 1:\n",
    "        return True\n",
    "    elif all(token in match_tokens for token in jersey_tokens) and len(jersey_tokens) > len(match_tokens):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def filter_multi_word_matches_by_jersey_tokens(jersey_tokens, potential_matches):\n",
    "    filtered_matches = []\n",
    "\n",
    "    for match in potential_matches:\n",
    "        # Split each match into tokens\n",
    "        match_tokens = match.split()\n",
    "\n",
    "        # Count the number of tokens that start with each character in jersey_tokens\n",
    "        match_token_start_chars = {token[0] for token in match_tokens}\n",
    "        #print(match_token_start_chars, f\"*{jersey_tokens}\")\n",
    "\n",
    "\n",
    "        #for token in jersey_tokens:\n",
    "         #   print(token, token[0] in match_token_start_chars)\n",
    "\n",
    "        # Check if the match contains at least one token for each character in jersey_tokens\n",
    "        if all(token[0] in match_token_start_chars for token in jersey_tokens):\n",
    "            filtered_matches.append(match)\n",
    "\n",
    "    return filtered_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_df['New Found Name'] = ''\n",
    "wrong_df['Status II'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_df[wrong_df['Status'] == 'SUCCESS']['Lookup Return Case'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "success_status_counter = 0\n",
    "for i in range(0, 1063):\n",
    "    names_found = []\n",
    "    num_identical_rows = 0\n",
    "    num_names_this = 0\n",
    "    index = i\n",
    "    row = wrong_df.loc[index]\n",
    "    # Extract relevant columns\n",
    "    match = row['Match']\n",
    "    date = row['Date']\n",
    "\n",
    "    if type(row['Found Name']) == str:\n",
    "        if row['Found Name'].startswith('['):\n",
    "            FOUND_NAME = eval(row['Found Name']) \n",
    "        else:\n",
    "            FOUND_NAME = row['Found Name']\n",
    "    \n",
    "    if row['Status II'] != 'Done':\n",
    "    \n",
    "        if row['Status'] == 'SUCCESS':\n",
    "            #for all the success guys. \n",
    "            #these are all people that eventually T needs to use imputing methods.   \n",
    "            NAMES_FOUND = row['Name(s) Found']\n",
    "\n",
    "            ORIGINAL_JERSEY = row['ORIGINAL JERSEY']\n",
    "            if ORIGINAL_JERSEY == 'evčík':\n",
    "                ORIGINAL_JERSEY = 'P Ševčík'\n",
    "            this_country_code = row['Team Country Code']\n",
    "            if pd.isna(this_country_code):\n",
    "                country_name = 'Namibia'\n",
    "            else:\n",
    "                country_name = countries_codes[countries_codes[' Code'] == this_country_code]['Country'].unique()[0]\n",
    "            dataset_nationality = leagues_value[leagues_value['Team 1 Code'] == this_country_code]['Name'].unique()\n",
    "            if 'Mohd' in ORIGINAL_JERSEY:\n",
    "                ORIGINAL_JERSEY = ORIGINAL_JERSEY.replace('Mohd', 'Mohammed')\n",
    "            if type(FOUND_NAME) == list:\n",
    "                if NAMES_FOUND.startswith('['):\n",
    "                    for name in eval(NAMES_FOUND):\n",
    "                        FOUND_NAME.append(name)\n",
    "                else:\n",
    "                    FOUND_NAME.append(NAMES_FOUND)\n",
    "                found_names = FOUND_NAME\n",
    "            else:\n",
    "                found_names = [FOUND_NAME, NAMES_FOUND]\n",
    "            closest_name = filter_multi_word_matches_by_jersey_tokens([token[0] for token in ORIGINAL_JERSEY.split(' ')], found_names)\n",
    "\n",
    "            threshold_last_name = threshold_player_match(ORIGINAL_JERSEY.split(' ')[-1], dataset_nationality)[0]\n",
    "            if closest_name != []:\n",
    "                intersection = [name for name in closest_name if name in found_names]\n",
    "            else:\n",
    "                intersection = [name for name in found_names if name in threshold_last_name]\n",
    "\n",
    "            \n",
    "            if list(set(intersection)) != []:\n",
    "                if len(list(set(intersection))) == 1 and list(set(intersection)) != ['No matches found even with the lowest threshold.']:\n",
    "                    if ORIGINAL_JERSEY == 'Mudir Al Radaei':\n",
    "                        intersection = ['Mudir Abdurabu']\n",
    "                    elif ORIGINAL_JERSEY == 'Noel-Mc Leod':\n",
    "                        intersection = ['Kraig Noel-McLeod']\n",
    "                    elif ORIGINAL_JERSEY == 'Nguyn Tin Duy':\n",
    "                        intersection = ['Tien Duy Nguyen']\n",
    "                    elif ORIGINAL_JERSEY == 'Abbas Al Hassan':\n",
    "                        intersection = ['Abbas Al-Hassan']\n",
    "                    elif ORIGINAL_JERSEY == 'Angel':\n",
    "                        intersection = ['Wilker Ángel']\n",
    "\n",
    "                    print(i, ORIGINAL_JERSEY, closest_name, found_names)\n",
    "                    print(i, f'intersection of lists is says{list(set(intersection))}')\n",
    "\n",
    "                    success_status_counter += 1\n",
    "                    wrong_df.at[i, 'New Found Name'] = list(set(intersection))[0]\n",
    "                    wrong_df.at[i, 'Status II'] = 'Done - New'\n",
    "                else:\n",
    "                    #16 cases here left\n",
    "                    filtered_names_match_date = filter_using_date_of_match(list(set(intersection)), row['Nationality'], date, False)[1]\n",
    "                    # if type(filtered_names_match_date) == str:\n",
    "                    print(i, ORIGINAL_JERSEY, closest_name, found_names)\n",
    "                    print(i, f'FILTERED intersection of lists is says{filtered_names_match_date}')\n",
    "                    wrong_df.at[i, 'New Found Name'] = filtered_names_match_date#[name for name in closest_name if name in found_names][0]\n",
    "                    wrong_df.at[i, 'Status II'] = 'Done - Match Date Filtered'\n",
    "                    success_status_counter += 1\n",
    "            else:\n",
    "                0==0 #18 cases here\n",
    "                success_status_counter += 1\n",
    "                print(i, wrong_df.at[i, 'Date'], wrong_df.at[i, 'Nationality'], wrong_df.at[i, 'Match'], ORIGINAL_JERSEY, closest_name, found_names)\n",
    "                print(i, f'lists is says{found_names}')\n",
    "            \n",
    "        else:\n",
    "        \n",
    "                      \n",
    "            NAMES_FOUND = row['Name(s) Found']\n",
    "\n",
    "            ORIGINAL_JERSEY = row['ORIGINAL JERSEY']\n",
    "            if ORIGINAL_JERSEY == 'evčík':\n",
    "                ORIGINAL_JERSEY = 'P Ševčík'\n",
    "            this_country_code = row['Team Country Code']\n",
    "            if pd.isna(this_country_code):\n",
    "                country_name = 'Namibia'\n",
    "            else:\n",
    "                country_name = countries_codes[countries_codes[' Code'] == this_country_code]['Country'].unique()[0]\n",
    "            dataset_nationality = leagues_value[leagues_value['Team 1 Code'] == this_country_code]['Name'].unique()\n",
    "            if 'Mohd' in ORIGINAL_JERSEY:\n",
    "                ORIGINAL_JERSEY = ORIGINAL_JERSEY.replace('Mohd', 'Mohammed')\n",
    "            if type(FOUND_NAME) == list:\n",
    "                if NAMES_FOUND.startswith('['):\n",
    "                    for name in eval(NAMES_FOUND):\n",
    "                        FOUND_NAME.append(name)\n",
    "                else:\n",
    "                    FOUND_NAME.append(NAMES_FOUND)\n",
    "                found_names = FOUND_NAME\n",
    "            else:\n",
    "                found_names = [FOUND_NAME, NAMES_FOUND]\n",
    "            closest_name = filter_multi_word_matches_by_jersey_tokens([token[0] for token in ORIGINAL_JERSEY.split(' ')], found_names)\n",
    "     \n",
    "            if len(closest_name) == 1:\n",
    "                print(i, ORIGINAL_JERSEY, [name for name in closest_name if name in found_names]) #closest_name, found_names\n",
    "                success_status_counter += 1\n",
    "                \n",
    "                #wrong_df['Status 2'] MAKE A NEW STATUS TO MARK THEM OFF ONCE DONE  \n",
    "            else:\n",
    "                print(i)\n",
    "                \n",
    "                threshold_last_name = threshold_player_match(ORIGINAL_JERSEY.split(' ')[-1], dataset_nationality)[0]\n",
    "                if closest_name != []:\n",
    "                    intersection = [name for name in closest_name if name in found_names and name in threshold_last_name]\n",
    "                else:\n",
    "                    intersection = [name for name in found_names if name in threshold_last_name]\n",
    "                if len(list(set(intersection))) == 2:\n",
    "                    \n",
    "                    filtered_names_match_date = filter_using_date_of_match(list(set(intersection)), row['Nationality'], date, False)[1]\n",
    "                    if type(filtered_names_match_date) == str:\n",
    "                        print(i, ORIGINAL_JERSEY, closest_name, found_names)\n",
    "                        print(i, f'SINGLE - filtered bymatch date - intersection of lists is says{filtered_names_match_date}')\n",
    "                        wrong_df.at[i, 'New Found Name'] = filtered_names_match_date#[name for name in closest_name if name in found_names][0]\n",
    "                        wrong_df.at[i, 'Status II'] = 'Done - Match Date Filtered'\n",
    "                    \n",
    "                        success_status_counter += 1\n",
    "                    elif type(filtered_names_match_date) == list:\n",
    "                        0==0\n",
    "                        print(i, ORIGINAL_JERSEY, closest_name, found_names)\n",
    "                        print(i, f'MULTI - filtered bymatch date - intersection of lists is says{filtered_names_match_date}')\n",
    "                        wrong_df.at[i, 'New Found Name'] = filtered_names_match_date#[name for name in closest_name if name in found_names][0]\n",
    "                        wrong_df.at[i, 'Status II'] = 'Done - Match Date Filtered'\n",
    "                        success_status_counter += 1\n",
    "                else:\n",
    "                    filtered_names_match_date = filter_using_date_of_match(list(set(intersection)), row['Nationality'], date, False)[1]\n",
    "                    print(i, ORIGINAL_JERSEY, closest_name, found_names)\n",
    "                    print(i, f'FILTERED intersection of lists is says{filtered_names_match_date}')\n",
    "                    success_status_counter += 1\n",
    "                    #wrong_df.at[i, 'New Found Name'] = filtered_names_match_date#[name for name in closest_name if name in found_names][0]\n",
    "                    #wrong_df.at[i, 'Status II'] = 'Done - Match Date Filtered'\n",
    "\n",
    "\n",
    "                #print(i, f\"threshold match says {threshold_player_match(ORIGINAL_JERSEY, found_names)}\")\n",
    "print(success_status_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match ID</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Match</th>\n",
       "      <th>Date</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Team Country Code</th>\n",
       "      <th>Season</th>\n",
       "      <th>Status</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Value</th>\n",
       "      <th>Lookup Still Required?</th>\n",
       "      <th>Lookup Return Case</th>\n",
       "      <th>Impute Required?</th>\n",
       "      <th>Name(s) Found</th>\n",
       "      <th>ORIGINAL JERSEY</th>\n",
       "      <th>Match Case</th>\n",
       "      <th>Wrong Name</th>\n",
       "      <th>Found Name</th>\n",
       "      <th>New Found Name</th>\n",
       "      <th>Status II</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3147</td>\n",
       "      <td>World Cup Qualifiers, Europe, 2018</td>\n",
       "      <td>San Marino vs Czech Republic</td>\n",
       "      <td>26-03-2017</td>\n",
       "      <td>San Marino</td>\n",
       "      <td>SM</td>\n",
       "      <td>2017</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Davide Simoncini</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Large Dataset had 0</td>\n",
       "      <td>False</td>\n",
       "      <td>Davide Simoncini</td>\n",
       "      <td>D Simoncini</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['Aldo Simoncini']</td>\n",
       "      <td>Davide Simoncini</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3147</td>\n",
       "      <td>World Cup Qualifiers, Europe, 2018</td>\n",
       "      <td>San Marino vs Czech Republic</td>\n",
       "      <td>26-03-2017</td>\n",
       "      <td>San Marino</td>\n",
       "      <td>SM</td>\n",
       "      <td>2017</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Fabio Vitaioli</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Large Dataset had 0</td>\n",
       "      <td>False</td>\n",
       "      <td>Fabio Vitaioli</td>\n",
       "      <td>F Vitaioli</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['Matteo Vitaioli']</td>\n",
       "      <td>Fabio Vitaioli</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2685</td>\n",
       "      <td>World Cup Qualifiers, Asia, 2022</td>\n",
       "      <td>Maldives vs Guam</td>\n",
       "      <td>19-11-2019</td>\n",
       "      <td>Guam</td>\n",
       "      <td>GU</td>\n",
       "      <td>2019</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Shawn Nicklaw</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Large Dataset had 0</td>\n",
       "      <td>False</td>\n",
       "      <td>Shawn Nicklaw</td>\n",
       "      <td>S Nicklaw</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['Travis Nicklaw']</td>\n",
       "      <td>Shawn Nicklaw</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2685</td>\n",
       "      <td>World Cup Qualifiers, Asia, 2022</td>\n",
       "      <td>Maldives vs Guam</td>\n",
       "      <td>19-11-2019</td>\n",
       "      <td>Guam</td>\n",
       "      <td>GU</td>\n",
       "      <td>2019</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Nate Lee</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Large Dataset had 0</td>\n",
       "      <td>False</td>\n",
       "      <td>Nate Lee</td>\n",
       "      <td>N Lee</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['Justin Lee']</td>\n",
       "      <td>Nate Lee</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2685</td>\n",
       "      <td>World Cup Qualifiers, Asia, 2022</td>\n",
       "      <td>Maldives vs Guam</td>\n",
       "      <td>19-11-2019</td>\n",
       "      <td>Guam</td>\n",
       "      <td>GU</td>\n",
       "      <td>2019</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Jason Cunliffe</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Large Dataset had 0</td>\n",
       "      <td>False</td>\n",
       "      <td>Jason Cunliffe</td>\n",
       "      <td>J Cunliffe</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['A. J. DeLaGarza']</td>\n",
       "      <td>Jason Cunliffe</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>3715</td>\n",
       "      <td>Gold Cup, 2017</td>\n",
       "      <td>Costa Rica vs French Guyana</td>\n",
       "      <td>15-07-2017</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>CR</td>\n",
       "      <td>2017</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>Ariel Rodríguez</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Was in  DB before or after season</td>\n",
       "      <td>True</td>\n",
       "      <td>Ariel Rodríguez</td>\n",
       "      <td>A Rodríguez</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['Osvaldo Rodríguez', 'Francisco Rodríguez']</td>\n",
       "      <td>Ariel Rodríguez</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>2998</td>\n",
       "      <td>World Cup Qualifiers, Europe, 2018</td>\n",
       "      <td>Georgia vs Serbia</td>\n",
       "      <td>24-03-2017</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>RS</td>\n",
       "      <td>2017</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>Boris Radunović</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Was in  DB before or after season</td>\n",
       "      <td>True</td>\n",
       "      <td>Boris Radunović</td>\n",
       "      <td>B Ivanović</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['Branislav Ivanovic', 'Djordje Ivanovic']</td>\n",
       "      <td>Branislav Ivanovic</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>3008</td>\n",
       "      <td>World Cup Qualifiers, Europe, 2018</td>\n",
       "      <td>Serbia vs Wales</td>\n",
       "      <td>11-06-2017</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>RS</td>\n",
       "      <td>2017</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>Boris Radunović</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Was in  DB before or after season</td>\n",
       "      <td>True</td>\n",
       "      <td>Boris Radunović</td>\n",
       "      <td>B Ivanović</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['Branislav Ivanovic', 'Djordje Ivanovic']</td>\n",
       "      <td>Branislav Ivanovic</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>3024</td>\n",
       "      <td>World Cup Qualifiers, Europe, 2018</td>\n",
       "      <td>Serbia vs Moldova</td>\n",
       "      <td>02-09-2017</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>RS</td>\n",
       "      <td>2017</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>Boris Radunović</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Was in  DB before or after season</td>\n",
       "      <td>True</td>\n",
       "      <td>Boris Radunović</td>\n",
       "      <td>B Ivanović</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['Branislav Ivanovic', 'Djordje Ivanovic']</td>\n",
       "      <td>Branislav Ivanovic</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1482</td>\n",
       "      <td>Nations League 2018-2020</td>\n",
       "      <td>Romania vs Serbia</td>\n",
       "      <td>14.10.18</td>\n",
       "      <td>Romania</td>\n",
       "      <td>RO</td>\n",
       "      <td>2018</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>Alexandru Băluță</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Was in  DB before or after season</td>\n",
       "      <td>True</td>\n",
       "      <td>Alexandru Băluță</td>\n",
       "      <td>A Baluta</td>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>['Mihai Bălașa']</td>\n",
       "      <td>Alexandru Băluță</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Match ID                         Competition  \\\n",
       "0         3147  World Cup Qualifiers, Europe, 2018   \n",
       "1         3147  World Cup Qualifiers, Europe, 2018   \n",
       "2         2685    World Cup Qualifiers, Asia, 2022   \n",
       "3         2685    World Cup Qualifiers, Asia, 2022   \n",
       "4         2685    World Cup Qualifiers, Asia, 2022   \n",
       "...        ...                                 ...   \n",
       "1058      3715                      Gold Cup, 2017   \n",
       "1059      2998  World Cup Qualifiers, Europe, 2018   \n",
       "1060      3008  World Cup Qualifiers, Europe, 2018   \n",
       "1061      3024  World Cup Qualifiers, Europe, 2018   \n",
       "1062      1482            Nations League 2018-2020   \n",
       "\n",
       "                             Match        Date Nationality Team Country Code  \\\n",
       "0     San Marino vs Czech Republic  26-03-2017  San Marino                SM   \n",
       "1     San Marino vs Czech Republic  26-03-2017  San Marino                SM   \n",
       "2                 Maldives vs Guam  19-11-2019        Guam                GU   \n",
       "3                 Maldives vs Guam  19-11-2019        Guam                GU   \n",
       "4                 Maldives vs Guam  19-11-2019        Guam                GU   \n",
       "...                            ...         ...         ...               ...   \n",
       "1058   Costa Rica vs French Guyana  15-07-2017  Costa Rica                CR   \n",
       "1059             Georgia vs Serbia  24-03-2017      Serbia                RS   \n",
       "1060               Serbia vs Wales  11-06-2017      Serbia                RS   \n",
       "1061             Serbia vs Moldova  02-09-2017      Serbia                RS   \n",
       "1062             Romania vs Serbia    14.10.18     Romania                RO   \n",
       "\n",
       "      Season   Status              Name Market Value  Lookup Still Required?  \\\n",
       "0       2017  SUCCESS  Davide Simoncini            0                   False   \n",
       "1       2017  SUCCESS    Fabio Vitaioli            0                   False   \n",
       "2       2019  SUCCESS     Shawn Nicklaw            0                   False   \n",
       "3       2019  SUCCESS          Nate Lee            0                   False   \n",
       "4       2019  SUCCESS    Jason Cunliffe            0                   False   \n",
       "...      ...      ...               ...          ...                     ...   \n",
       "1058    2017     FAIL   Ariel Rodríguez            0                    True   \n",
       "1059    2017     FAIL   Boris Radunović            0                    True   \n",
       "1060    2017     FAIL   Boris Radunović            0                    True   \n",
       "1061    2017     FAIL   Boris Radunović            0                    True   \n",
       "1062    2018     FAIL  Alexandru Băluță            0                    True   \n",
       "\n",
       "                     Lookup Return Case  Impute Required?     Name(s) Found  \\\n",
       "0                   Large Dataset had 0             False  Davide Simoncini   \n",
       "1                   Large Dataset had 0             False    Fabio Vitaioli   \n",
       "2                   Large Dataset had 0             False     Shawn Nicklaw   \n",
       "3                   Large Dataset had 0             False          Nate Lee   \n",
       "4                   Large Dataset had 0             False    Jason Cunliffe   \n",
       "...                                 ...               ...               ...   \n",
       "1058  Was in  DB before or after season              True   Ariel Rodríguez   \n",
       "1059  Was in  DB before or after season              True   Boris Radunović   \n",
       "1060  Was in  DB before or after season              True   Boris Radunović   \n",
       "1061  Was in  DB before or after season              True   Boris Radunović   \n",
       "1062  Was in  DB before or after season              True  Alexandru Băluță   \n",
       "\n",
       "     ORIGINAL JERSEY Match Case Wrong Name  \\\n",
       "0        D Simoncini     single        Yes   \n",
       "1         F Vitaioli     single        Yes   \n",
       "2          S Nicklaw     single        Yes   \n",
       "3              N Lee     single        Yes   \n",
       "4         J Cunliffe     single        Yes   \n",
       "...              ...        ...        ...   \n",
       "1058     A Rodríguez     single        Yes   \n",
       "1059      B Ivanović     single        Yes   \n",
       "1060      B Ivanović     single        Yes   \n",
       "1061      B Ivanović     single        Yes   \n",
       "1062        A Baluta     single        Yes   \n",
       "\n",
       "                                        Found Name      New Found Name  \\\n",
       "0                               ['Aldo Simoncini']    Davide Simoncini   \n",
       "1                              ['Matteo Vitaioli']      Fabio Vitaioli   \n",
       "2                               ['Travis Nicklaw']       Shawn Nicklaw   \n",
       "3                                   ['Justin Lee']            Nate Lee   \n",
       "4                              ['A. J. DeLaGarza']      Jason Cunliffe   \n",
       "...                                            ...                 ...   \n",
       "1058  ['Osvaldo Rodríguez', 'Francisco Rodríguez']     Ariel Rodríguez   \n",
       "1059    ['Branislav Ivanovic', 'Djordje Ivanovic']  Branislav Ivanovic   \n",
       "1060    ['Branislav Ivanovic', 'Djordje Ivanovic']  Branislav Ivanovic   \n",
       "1061    ['Branislav Ivanovic', 'Djordje Ivanovic']  Branislav Ivanovic   \n",
       "1062                              ['Mihai Bălașa']    Alexandru Băluță   \n",
       "\n",
       "     Status II  \n",
       "0         Done  \n",
       "1         Done  \n",
       "2         Done  \n",
       "3         Done  \n",
       "4         Done  \n",
       "...        ...  \n",
       "1058      Done  \n",
       "1059      Done  \n",
       "1060      Done  \n",
       "1061      Done  \n",
       "1062      Done  \n",
       "\n",
       "[1063 rows x 20 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "wrong_df[wrong_df['Status II'] == 'Done']#.tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_df.to_csv('wrong_df_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#do the threshold match. if its either Name(s) found column or Found Name column use that name "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
