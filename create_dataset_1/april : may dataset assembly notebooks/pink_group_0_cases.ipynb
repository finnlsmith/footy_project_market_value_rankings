{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from countries_languages import country_to_language\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "import numpy as np\n",
    "import re\n",
    "from transliterate import translit\n",
    "from unidecode import unidecode\n",
    "import Levenshtein\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import wikipediaapi\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import difflib\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import calendar\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import AssemblyHelpers\n",
    "#from AssemblyHelpers import find_money_info_from_name\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def load_csv_dataset(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def find_close_matches_variable(this_jersey, dataset_nationality, threshold):\n",
    "    \"\"\"\n",
    "    Find close matches of `this_jersey` in `dataset_nationality` using Levenshtein distance.\n",
    "\n",
    "    Args:\n",
    "    - this_jersey (str): The string to find close matches for.\n",
    "    - dataset_nationality (list): List of strings to search for close matches in.\n",
    "    - threshold (int): Minimum similarity score required for a match (default is 90).\n",
    "\n",
    "    Returns:\n",
    "    - List of strings from `dataset_nationality` that are close matches to `this_jersey`.\n",
    "    \"\"\"\n",
    "    close_matches = process.extract(this_jersey, dataset_nationality, limit=None)\n",
    "    return [match[0] for match in close_matches if match[1] >= threshold]\n",
    "\n",
    "#threshold match one \n",
    "def threshold_player_match(this_jersey, dataset_nationality):\n",
    "    THRESHOLD_NUM = 89\n",
    "    #stops when it returns a name.\n",
    "    #if it doesnt find a match keep lowering the threshold until you find a match\n",
    "    #but if you get to threshold of like 50 first you stop and just abandon ship    \n",
    "\n",
    "    # Loop until someone is found or threshold goes below 50\n",
    "    while THRESHOLD_NUM >= 50:\n",
    "        matches = find_close_matches_variable(this_jersey, dataset_nationality, THRESHOLD_NUM)\n",
    "        if matches:\n",
    "            #print(f\"Player is {this_jersey}. Found matches: {matches}. threshold is {THRESHOLD_NUM}\")\n",
    "            return matches, THRESHOLD_NUM\n",
    "            #break\n",
    "        else:\n",
    "            THRESHOLD_NUM -= 1\n",
    "\n",
    "    # If threshold reaches below 50 without finding any matches\n",
    "    if THRESHOLD_NUM < 50:\n",
    "        return [f\"No matches found even with the lowest threshold.\"], this_jersey #jersey was {this_jersey}\n",
    "\n",
    "\n",
    "def filter_using_date_of_match(candidate_list_of_names_input, nationality_input, matchdate_Input, SALARY_BOOLEAN): \n",
    "\n",
    "    FILTERED_NAMES_USING_MATCH_DATE = AssemblyHelpers.multiNameMatchDateLookup(candidate_list_of_names_input, nationality_input, matchdate_Input) \n",
    "\n",
    "    #print('in fudom', type(FILTERED_NAMES_USING_MATCH_DATE))\n",
    "    #1 MATCH\n",
    "    if isinstance(FILTERED_NAMES_USING_MATCH_DATE, str) or isinstance(FILTERED_NAMES_USING_MATCH_DATE, np.str_): #YELLOW 3\n",
    "        #print('were here', FILTERED_NAMES_USING_MATCH_DATE)\n",
    "        #print('were in fudom in the right place')\n",
    "        #NAME_FOR_SELENIUM_SEARCH = FILTERED_NAMES_USING_MATCH_DATE\n",
    "        # MONEY_FOUND_ONLINE = useSeleniumToFindMoney(NAME_FOR_SELENIUM_SEARCH, nationality_input, matchdate_Input, SALARY_BOOLEAN)\n",
    "        # print('made it out of using selenium')\n",
    "        # money_thisplayer = [MONEY_FOUND_ONLINE, f'Online WAS Lookup Required - salary boolean is {SALARY_BOOLEAN}', True, False]\n",
    "        money_thisplayer = [0, 'Lookup Required', True, False]\n",
    "        return money_thisplayer, FILTERED_NAMES_USING_MATCH_DATE\n",
    "    #MULTIPLE MATCHES\n",
    "    elif(len(FILTERED_NAMES_USING_MATCH_DATE) >= 2):\n",
    "        print(FILTERED_NAMES_USING_MATCH_DATE, type(FILTERED_NAMES_USING_MATCH_DATE), type(FILTERED_NAMES_USING_MATCH_DATE) == str)\n",
    "        money_thisplayer = [0, F'FILTERING USING MATCH DATE LEFT MULTIPLE RESULTS: {FILTERED_NAMES_USING_MATCH_DATE}', True, False]\n",
    "        return money_thisplayer, FILTERED_NAMES_USING_MATCH_DATE\n",
    "    #0 MATCHES\n",
    "    elif(len(FILTERED_NAMES_USING_MATCH_DATE) == 0):\n",
    "        money_thisplayer = [0, F'FILTERING USING MATCH DATE LEFT 0 RESULTS. BEFORE FILTERING, CANDIDATE NAMES WERE {candidate_list_of_names_input}', True, False]\n",
    "        return money_thisplayer, ''\n",
    "    \n",
    "\n",
    "def check_tokens(this_jersey, match):\n",
    "    jersey_tokens = this_jersey.lower().split()\n",
    "    match_tokens = match.lower().split()\n",
    "    \n",
    "    if all(token in match_tokens for token in jersey_tokens):\n",
    "        return True\n",
    "    elif all(token in jersey_tokens for token in match_tokens) and len(jersey_tokens) == len(match_tokens) + 1:\n",
    "        return True\n",
    "    elif all(token in match_tokens for token in jersey_tokens) and len(jersey_tokens) > len(match_tokens):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def filter_multi_word_matches_by_jersey_tokens(jersey_tokens, potential_matches):\n",
    "    filtered_matches = []\n",
    "\n",
    "    for match in potential_matches:\n",
    "        # Split each match into tokens\n",
    "        match_tokens = match.split()\n",
    "\n",
    "        # Count the number of tokens that start with each character in jersey_tokens\n",
    "        match_token_start_chars = {token[0] for token in match_tokens}\n",
    "        #print(match_token_start_chars, f\"*{jersey_tokens}\")\n",
    "\n",
    "        #for token in jersey_tokens:\n",
    "        #   print(token, token[0] in match_token_start_chars)\n",
    "\n",
    "        # Check if the match contains at least one token for each character in jersey_tokens\n",
    "        if all(token[0] in match_token_start_chars for token in jersey_tokens):\n",
    "            filtered_matches.append(match)\n",
    "\n",
    "    return filtered_matches\n",
    "\n",
    "def last_name_match(name, dataset_of_names):\n",
    "    matching_names = []\n",
    "    for full_name in dataset_of_names:\n",
    "        \n",
    "        # Split the full name into tokens\n",
    "        full_name_tokens = set(re.split(r'\\s+|[-–]', full_name))\n",
    "        \n",
    "        # Check if any token matches the last name or its unidecoded version\n",
    "        for token in full_name_tokens:\n",
    "            #if full_name == 'Fródi Benjaminsen':\n",
    "                #print(token, name, token == name)\n",
    "                #print(full_name_tokens)\n",
    "            \n",
    "            if token == name or unidecode(token) == name:\n",
    "                matching_names.append(full_name)\n",
    "                break  # Once a match is found, move to the next name\n",
    "    return matching_names\n",
    "\n",
    "def check_other_team(lookup_row, transfermarkt_data, results_df):\n",
    "    new_rows = []\n",
    "    wrong_rows = []\n",
    "\n",
    "    name = lookup_row['Name']\n",
    "    original_jersey = lookup_row['ORIGINAL JERSEY']\n",
    "    season = lookup_row['Season']\n",
    "    original_country_code = lookup_row['Team Country Code']\n",
    "    match_id = lookup_row['Match ID']\n",
    "    opposing_country_code = \"\"\n",
    "    game_row = results_df[results_df['Match ID'] == match_id]\n",
    "    #print(game_row)\n",
    "    \n",
    "    if len(game_row) != 1:\n",
    "        raise ValueError(\"There should only be one match per ID\")\n",
    "\n",
    "    #print(original_country_code)\n",
    "    team2_code = game_row.iloc[0]['Team 2 Code']\n",
    "    team1_code = game_row.iloc[0]['Team 1 Code']\n",
    "\n",
    "    #print(f\"1{team1_code}, 2{team2_code}\")\n",
    "    if original_country_code == 'CG':\n",
    "        original_country_code = ' CG'\n",
    "    elif original_country_code  == 'NI':\n",
    "        original_country_code = ' NI'\n",
    "    if original_country_code == team1_code:\n",
    "        opposing_country_code = team2_code\n",
    "    elif original_country_code == team2_code:\n",
    "        opposing_country_code = team1_code\n",
    "    else:\n",
    "        raise ValueError(\"Original country code does not match any team in the match\")\n",
    "\n",
    "    dataset_nationality = transfermarkt_data[transfermarkt_data['Team 1 Code'] == opposing_country_code]['Name'].unique()\n",
    "    possible_names = threshold_player_match(original_jersey, dataset_nationality)\n",
    "    \n",
    "    return possible_names[0]\n",
    "\n",
    "def add_correct_money(money_column):\n",
    "    if money_column == 0:\n",
    "        return 0\n",
    "\n",
    "    if 'm' in money_column:\n",
    "        value_rough = money_column.split('m')[0].split('€')[1]\n",
    "        millinum = (float(value_rough) * 1000000)\n",
    "        return millinum\n",
    "    elif 'k' in money_column:\n",
    "        #print(i, 'k')\n",
    "        value_rough = money_column.split('k')[0].split('€')[1]\n",
    "        millinum = (float(value_rough) * 1000)\n",
    "\n",
    "        return millinum\n",
    "    elif '-' in money_column:\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def remove_nation(match, nation1):\n",
    "    # Split the match string by 'vs' and strip any leading or trailing spaces\n",
    "    parts = [part.strip() for part in match.split('vs')]\n",
    "    # Remove the nation1 from the list of parts\n",
    "    parts.remove(nation1)\n",
    "    # Join the remaining parts and return\n",
    "    return ''.join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/z2xv57_n70l_szw_fr80j5km0000gn/T/ipykernel_48300/813481528.py:9: DtypeWarning: Columns (4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  leagues_value_large = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/CSVs we use often/most_updated_transfermarkt_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "#loading CSVs\n",
    "\n",
    "#PLAYER DATA - MARKET VALUE AND SALARY\n",
    "leagues_salary = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1//CSVs we use often/latest_capology_data_money_fixed.csv')\n",
    "\n",
    "leagues_value = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/CSVs we use often/MarketValuesComplete.csv')\n",
    "\n",
    "\n",
    "leagues_value_large = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/CSVs we use often/most_updated_transfermarkt_dataset.csv')\n",
    "\n",
    "#COUNTRY CODES\n",
    "countries_codes = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/CSVs we use often/countries_and_codes.csv')\n",
    "\n",
    "#FIFA RANKINGS\n",
    "fifa_rankings = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/CSVs we use often/fifa_ranking-2023-10-26 - fifa_ranking-2023-07-20.csv')\n",
    "\n",
    "#MATCH DATA - LINEUPS AND RESULTS\n",
    "# lineups_data = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/CSVs we use often/newest_lineups_data_march_24.csv')\n",
    "lineups_data = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/CSVs we use often/newest_lineups_data_april_29.csv')\n",
    "results_data = pd.read_csv('/Users/finneganlaister-smith/Downloads/DEV ENVIRONMENT/data-science-jupyter-template-main/footy_project_market_value_rankings/create_dataset_1/CSVs we use often/newest_results_data_march_24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/z2xv57_n70l_szw_fr80j5km0000gn/T/ipykernel_48300/931677539.py:49: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "combined_df = load_csv_dataset('combined_df_may_1.csv')\n",
    "combined_df = combined_df.drop(columns={'Unnamed: 0'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weird 0 Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_group_0_cases = load_csv_dataset('April 25 - CONCACAF & CONMEBOL OUT - DATA CSVs/Pink Group/CONCACAF & CONMEBOL OUT - odd_name_found_0_cases.csv')\n",
    "pink_group_0_cases = pink_group_0_cases.drop(columns={'Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'To Remove'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pink_group_0_cases.iterrows():\n",
    "    if row['Nationality'] == 'Namibia':\n",
    "        pink_group_0_cases.at[index, 'Team Country Code'] = 'NB'\n",
    "    elif row['Nationality'] == 'Congo':\n",
    "        pink_group_0_cases.at[index, 'Nationality'] = 'Republic of the Congo'\n",
    "    elif row['Nationality'] == 'Republic of the Congo':\n",
    "        pink_group_0_cases.at[index, 'Team Country Code'] = 'CG'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_group_0_cases['Status New'] = ''\n",
    "\n",
    "pink_group_0_cases['Market Value New'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vet_group_using_initials(jersey, names_found, names_same_nation_last_name):\n",
    "    correct_names_list = []\n",
    "\n",
    "    jersey_tokens_initials = [token[0] for token in re.split(r'\\s+|[-–]', jersey)]\n",
    "\n",
    "    names_found_tokens_initials = [token[0] for token in re.split(r'\\s+|[-–]', names_found)]\n",
    "\n",
    "    for name in names_same_nation_last_name:\n",
    "        name_initials = [token[0] for token in re.split(r'\\s+|[-–]', name)]\n",
    "        \n",
    "        if set(jersey_tokens_initials) == set(name_initials):\n",
    "            correct_names_list.append(name)\n",
    "        elif set(jersey_tokens_initials).issubset(set(name_initials)):\n",
    "            correct_names_list.append(name)\n",
    "        #else:\n",
    "            #print('fail')\n",
    "\n",
    "    if set(jersey_tokens_initials) == set(names_found_tokens_initials):\n",
    "        correct_names_list.append(names_found)\n",
    "    elif set(jersey_tokens_initials).issubset(set(names_found_tokens_initials)):\n",
    "            correct_names_list.append(names_found)\n",
    "\n",
    "\n",
    "    return correct_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_counter = 0\n",
    "done_counter = 0\n",
    "for index, row in pink_group_0_cases.iterrows():\n",
    "    \n",
    "    if row['Status New'] != 'Done':\n",
    "        correct_name = ''\n",
    "        player_this = row['ORIGINAL JERSEY']\n",
    "        if player_this == 'Král':\n",
    "            player_this = 'Alex Kral'\n",
    "        elif player_this == 'Oršić':\n",
    "            player_this = 'Mislav Orsic'\n",
    "        elif player_this == 'Višća':\n",
    "            player_this = 'Edin Visca'\n",
    "        elif player_this == 'evčík':\n",
    "            player_this = 'Petr Sevcik'\n",
    "        nationality = row['Nationality']\n",
    "        date = row['Date']\n",
    "        match = row['Match']\n",
    "        \n",
    "        full_num = row['Season']\n",
    "        \n",
    "        if nationality == 'Republic of the Congo' or nationality == 'Namibia':\n",
    "            country_code_this = row['Team Country Code']\n",
    "            dataset_nationality = leagues_value[(leagues_value['Team 1 Code'] == country_code_this) & \n",
    "                                        (leagues_value['Season'].isin([full_num, full_num + 1, full_num - 1]))]['Name'].unique()\n",
    "            \n",
    "            best_match = threshold_player_match(player_this, dataset_nationality)[0]\n",
    "            \n",
    "            if len(best_match) == 1:\n",
    "                correct_name = best_match[0]\n",
    "                print(index, nationality, player_this)\n",
    "                #print(index, best_match)\n",
    "            else:\n",
    "                print(index, nationality, player_this)\n",
    "                #print(index, best_match)\n",
    "\n",
    "                last_name = re.split(r'\\s+|[-–]', player_this)[-1]\n",
    "            # #TRY TO FIND OTHER PLAYERS FROM THE NATION W THE SAME LAST NAME\n",
    "                names_same_nation_last_name = last_name_match(last_name, dataset_nationality)\n",
    "\n",
    "                vetted_list_using_initials = vet_group_using_initials(player_this, player_this, best_match)\n",
    "                if player_this in vetted_list_using_initials:\n",
    "                    vetted_list_using_initials.remove(player_this)\n",
    "                #print(index, vetted_list_using_initials)\n",
    "                correct_name = vetted_list_using_initials[0]\n",
    "            \n",
    "\n",
    "            number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value)\n",
    "            #print(player_this, reason, add_correct_money(number))\n",
    "\n",
    "            #add a new row to lookup dataset 1 \n",
    "            if type(number) == float:\n",
    "                0==0\n",
    "            else:\n",
    "                number = add_correct_money(number)\n",
    "            print('**')\n",
    "            print(index, player_this, correct_name, number, reason)\n",
    "            if reason == 'Found in Curr Season':\n",
    "                pink_group_0_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                pink_group_0_cases.at[index, 'Status New'] = 'Done'\n",
    "                pink_group_0_cases.at[index, 'Market Value New'] = number\n",
    "                pink_group_0_cases.at[index, 'Match Case'] = 'single'\n",
    "                success_counter += 1\n",
    "                \n",
    "        else:\n",
    "            country_code_this = row['Team Country Code']\n",
    "            dataset_nationality = leagues_value[(leagues_value['Team 1 Code'] == country_code_this) & \n",
    "                                        (leagues_value['Season'].isin([full_num, full_num + 1, full_num - 1]))]['Name'].unique()\n",
    "            \n",
    "            best_match = threshold_player_match(player_this, dataset_nationality)[0]\n",
    "            \n",
    "            if len(best_match) >= 2:\n",
    "                print(index, best_match)\n",
    "                vetted_list_using_initials = vet_group_using_initials(player_this, player_this, best_match)\n",
    "                if player_this in vetted_list_using_initials:\n",
    "                    vetted_list_using_initials.remove(player_this)\n",
    "                \n",
    "                for name in vetted_list_using_initials:\n",
    "                    if player_this in unidecode(name):\n",
    "                        0==0\n",
    "                    elif unidecode(player_this) in name:\n",
    "                        0==0\n",
    "                    else:\n",
    "                        vetted_list_using_initials.remove(name)\n",
    "                if len(vetted_list_using_initials) == 1:\n",
    "                    correct_name = vetted_list_using_initials[0]\n",
    "                #print(index, nationality, player_this, vetted_list_using_initials)\n",
    "\n",
    "                number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value)\n",
    "                #print(player_this, reason, add_correct_money(number))\n",
    "\n",
    "                #add a new row to lookup dataset 1 \n",
    "                if type(number) == float:\n",
    "                    0==0\n",
    "                else:\n",
    "                    number = add_correct_money(number)\n",
    "                print('**')\n",
    "                print(index, player_this, correct_name, number, reason)\n",
    "                if reason == 'Found in Curr Season':\n",
    "                    pink_group_0_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                    pink_group_0_cases.at[index, 'Status New'] = 'Done'\n",
    "                    pink_group_0_cases.at[index, 'Market Value New'] = number\n",
    "                    pink_group_0_cases.at[index, 'Match Case'] = 'single'\n",
    "                    success_counter += 1\n",
    "                \n",
    "            else:\n",
    "                #print(index, player_this, best_match)\n",
    "                correct_name = best_match[0]\n",
    "                number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value)\n",
    "                #success_counter += 1\n",
    "                if type(number) == float:\n",
    "                    0==0\n",
    "                else:\n",
    "                    number = add_correct_money(number)\n",
    "                print('**')\n",
    "                print(index, player_this, correct_name, number, reason)\n",
    "                if reason == 'Found in Curr Season':\n",
    "                    pink_group_0_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                    pink_group_0_cases.at[index, 'Status New'] = 'Done'\n",
    "                    pink_group_0_cases.at[index, 'Market Value New'] = number\n",
    "                    pink_group_0_cases.at[index, 'Match Case'] = 'single'\n",
    "                    success_counter += 1\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "                # if len(vetted_list_using_initials) == 1:\n",
    "                #     correct_name = vetted_list_using_initials[0]\n",
    "                # elif len(vetted_list_using_initials) >= 2:\n",
    "                #     initial_double_letters = multiple_occurrences(jersey_tokens_initials)\n",
    "                #     vetted_list_using_initials = vet_using_repeated_letters(initial_double_letters, vetted_list_using_initials)\n",
    "    else:\n",
    "        done_counter += 1\n",
    "print(success_counter, done_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(pink_group_0_cases)):\n",
    "    if pink_group_0_cases.at[i, 'Market Value New'] != 0:\n",
    "        if pink_group_0_cases.at[i, 'Market Value New'] != pink_group_0_cases.at[i, 'Market Value']:\n",
    "            print(i)\n",
    "        #print(pink_group_0_cases.at[i, 'Market Value New'], pink_group_0_cases.at[i, 'Market Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_group_0_cases[pink_group_0_cases['Status New'] == 'Done']['Lookup Return Case'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(pink_group_0_cases)):\n",
    "    if pink_group_0_cases.at[i, 'Market Value'] == pink_group_0_cases.at[i, 'Market Value New']:\n",
    "        0==0\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_group_0_cases_final = pink_group_0_cases.drop(columns={'Status New', 'Market Value New'})\n",
    "pink_group_0_cases_final.to_csv('pink_group_weird_0_cases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Lookup - 0 Names Found one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_group_lookup_cases = load_csv_dataset('April 25 - CONCACAF & CONMEBOL OUT - DATA CSVs/Pink Group/pink_group_lookup_cases.csv')\n",
    "#pink_group_lookup_cases = pink_group_lookup_cases.drop(columns={'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'To Remove'})\n",
    "#pink_group_lookup_cases['Status New'] = ''\n",
    "# pink_group_lookup_cases['Market Value New'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pink_group_lookup_cases.iterrows():\n",
    "    if row['Nationality'] == 'Namibia':\n",
    "        pink_group_lookup_cases.at[index, 'Team Country Code'] = 'NB'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in pink_group_lookup_cases.iterrows():\n",
    "    if 'Olympics' in row['Competition']:\n",
    "        pink_group_lookup_cases.at[index, 'Match Case'] = 'Olympic'\n",
    "    elif 'U-20' in row['Competition']:\n",
    "        pink_group_lookup_cases.at[index, 'Match Case'] = 'U-20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 2019 Henok Goitom ['No matches found even with the lowest threshold.']\n",
      "155 2019 Henok Goitom ['No matches found even with the lowest threshold.']\n",
      "2 0 222\n"
     ]
    }
   ],
   "source": [
    "case_counter = 0\n",
    "success_counter = 0\n",
    "done_cases = 0\n",
    "for index,row in pink_group_lookup_cases.iterrows():\n",
    "    if row['Match Case'] == 'Olympic' or row['Match Case'] == 'U-20':\n",
    "        if row['Status New'] != 'Done':\n",
    "            case_counter += 1\n",
    "            name_player = row['ORIGINAL JERSEY']\n",
    "            full_num = row['Season']\n",
    "            country_code_this = row['Team Country Code']\n",
    "\n",
    "            dataset_nationality = leagues_value_large[(leagues_value_large['Team 1 Code'] == country_code_this) & \n",
    "                (leagues_value['Season'].isin([full_num, full_num + 1, full_num - 1]))]['Name'].unique()\n",
    "            if name_player in dataset_nationality:\n",
    "                print(index, name_player, full_num, 'in dataset nationality')\n",
    "                correct_name = name_player\n",
    "                #if they are here, add their $ info. \n",
    "                number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value_large)\n",
    "                #success_counter += 1\n",
    "                if type(number) == float:\n",
    "                    0==0\n",
    "                else:\n",
    "                    number = add_correct_money(number)\n",
    "                \n",
    "                if reason == 'Found in Curr Season':\n",
    "                    print('**')\n",
    "                    print(index, correct_name, number, reason)\n",
    "                    pink_group_lookup_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                    pink_group_lookup_cases.at[index, 'Status New'] = 'Done'\n",
    "                    pink_group_lookup_cases.at[index, 'Lookup Return Case'] = reason\n",
    "                    pink_group_lookup_cases.at[index, 'Market Value New'] = number\n",
    "                    # pink_group_lookup_cases.at[index, 'Match Case'] = 'single'\n",
    "                    #success_counter += 1\n",
    "                else:\n",
    "                    success_counter += 1\n",
    "                    print(index, correct_name, number, reason)\n",
    "                    pink_group_lookup_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                    pink_group_lookup_cases.at[index, 'Lookup Return Case'] = 'Did Not Find in Curr Season, One Up or One Down'\n",
    "                    pink_group_lookup_cases.at[index, 'Status New'] = 'Done'\n",
    "                    pink_group_lookup_cases.at[index, 'Status'] = 'FAIL - LARGE'\n",
    "                    #if theyre in the dataset in general but not in the seasons we want:\n",
    "                        #set status column to FAIL - NEW. and set the Lookup Return case to Did Not Find in Curr Season, One Up or One Down - Use Large Dataset\n",
    "\n",
    "\n",
    "            elif name_player in leagues_value_large['Name'].unique():\n",
    "                0==0\n",
    "                success_counter += 1\n",
    "                print(index, name_player, full_num, 'in huge dataset')\n",
    "                pink_group_lookup_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                pink_group_lookup_cases.at[index, 'Lookup Return Case'] = 'Did Not Find in Curr Season, One Up or One Down'\n",
    "                pink_group_lookup_cases.at[index, 'Status New'] = 'Done'\n",
    "                pink_group_lookup_cases.at[index, 'Status'] = 'FAIL - LARGE'\n",
    "                \n",
    "                #if theyre in the dataset in general but not in the seasons we want:\n",
    "                    #set status column to FAIL - LARGE. and set the Lookup Return case to Did Not Find in Curr Season, One Up or One Down - Use Large Dataset\n",
    "\n",
    "            else:\n",
    "                0==0\n",
    "                success_counter += 1\n",
    "                \n",
    "                correct_name = threshold_player_match(name_player, dataset_nationality)[0][0]\n",
    "                number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value_large)\n",
    "                print(index,name_player, correct_name, number, reason)\n",
    "                pink_group_lookup_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                pink_group_lookup_cases.at[index, 'Status New'] = 'Done'\n",
    "                pink_group_lookup_cases.at[index, 'Lookup Return Case'] = reason\n",
    "                pink_group_lookup_cases.at[index, 'Market Value New'] = number\n",
    "                \n",
    "        else:\n",
    "            done_cases += 1\n",
    "    elif row['Nationality'] == 'Namibia' or row['Nationality'] == 'Republic of the Congo':\n",
    "        if row['Status New'] != 'Done':\n",
    "            \n",
    "            \n",
    "            case_counter += 1\n",
    "            correct_name = ''\n",
    "            name_player = row['ORIGINAL JERSEY']\n",
    "            full_num = row['Season']\n",
    "            country_code_this = row['Team Country Code']\n",
    "\n",
    "            dataset_nationality = leagues_value[(leagues_value['Team 1 Code'] == country_code_this) & \n",
    "                (leagues_value['Season'].isin([full_num, full_num + 1, full_num - 1]))]['Name'].unique()\n",
    "            best_match = threshold_player_match(name_player, dataset_nationality)[0]\n",
    "            \n",
    "            if len(best_match) == 1:\n",
    "                correct_name = best_match[0]\n",
    "                #print(index, name_player, correct_name)\n",
    "                #print(index, best_match)\n",
    "            else:\n",
    "                #print(index, nationality, name_player)\n",
    "                #print(index, best_match)\n",
    "\n",
    "                \n",
    "            # #TRY TO FIND OTHER PLAYERS FROM THE NATION W THE SAME LAST NAME\n",
    "                last_name = re.split(r'\\s+|[-–]', name_player)[-1]\n",
    "                names_same_nation_last_name = last_name_match(last_name, dataset_nationality)\n",
    "\n",
    "                vetted_list_using_initials = vet_group_using_initials(name_player, name_player, best_match)\n",
    "                if name_player in vetted_list_using_initials:\n",
    "                    vetted_list_using_initials.remove(name_player)\n",
    "                #print(index, vetted_list_using_initials)\n",
    "                correct_name = vetted_list_using_initials[0]\n",
    "                #print(index, name_player, correct_name)\n",
    "            if correct_name in dataset_nationality:\n",
    "                success_counter += 1\n",
    "                print(index, name_player)\n",
    "                #print(index, name_player, correct_name, full_num, '***in dataset nationality')\n",
    "                number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value)\n",
    "                if type(number) == float:\n",
    "                    0==0\n",
    "                else:\n",
    "                    number = add_correct_money(number)\n",
    "\n",
    "                pink_group_lookup_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                pink_group_lookup_cases.at[index, 'Lookup Return Case'] = reason\n",
    "                pink_group_lookup_cases.at[index, 'Market Value New'] = number\n",
    "                pink_group_lookup_cases.at[index, 'Status New'] = 'Done'\n",
    "                pink_group_lookup_cases.at[index, 'Status'] = 'SUCCESS'\n",
    "            else:\n",
    "                case_counter += 1\n",
    "        else:\n",
    "            done_cases += 1    \n",
    "    else:\n",
    "        if row['Status New'] != 'Done':\n",
    "            case_counter += 1\n",
    "            correct_name = ''\n",
    "            name_player = row['ORIGINAL JERSEY']\n",
    "            full_num = row['Season']\n",
    "            country_code_this = row['Team Country Code']\n",
    "\n",
    "            dataset_nationality = leagues_value_large[(leagues_value_large['Team 1 Code'] == country_code_this) & \n",
    "                (leagues_value_large['Season'].isin([full_num, full_num + 1, full_num - 1]))]['Name'].unique()\n",
    "            best_match = threshold_player_match(name_player, dataset_nationality)[0]\n",
    "            \n",
    "            if len(best_match) == 1:\n",
    "                vetted_list_using_initials = vet_group_using_initials(name_player, name_player, best_match)\n",
    "                if name_player in vetted_list_using_initials:\n",
    "                    vetted_list_using_initials.remove(name_player)\n",
    "                if len(vetted_list_using_initials) == 1:\n",
    "                    success_counter += 1\n",
    "                    \n",
    "                    correct_name = vetted_list_using_initials[0]\n",
    "\n",
    "                    number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value)\n",
    "                    if type(number) == float:\n",
    "                        0==0\n",
    "                    else:\n",
    "                        number = add_correct_money(number)\n",
    "                    print(index, 'derp', name_player, vetted_list_using_initials, number, reason)\n",
    "\n",
    "                    pink_group_lookup_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                    pink_group_lookup_cases.at[index, 'Lookup Return Case'] = reason\n",
    "                    pink_group_lookup_cases.at[index, 'Market Value New'] = number\n",
    "                    pink_group_lookup_cases.at[index, 'Status New'] = 'Done'\n",
    "                    pink_group_lookup_cases.at[index, 'Status'] = 'SUCCESS'\n",
    "                else:\n",
    "                    print(index, full_num, name_player, best_match)\n",
    "\n",
    "\n",
    "                # last_name = re.split(r'\\s+|[-–]', name_player)[-1]\n",
    "                # names_same_nation_last_name = last_name_match(last_name, dataset_nationality)\n",
    "\n",
    "                # vetted_list_using_initials = vet_group_using_initials(name_player, name_player, names_same_nation_last_name)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                vetted_list_using_initials = vet_group_using_initials(name_player, name_player, best_match)\n",
    "                if name_player in vetted_list_using_initials:\n",
    "                    vetted_list_using_initials.remove(name_player)\n",
    "                if vetted_list_using_initials == []:\n",
    "                    print(index, 'hmm', name_player)\n",
    "                else:\n",
    "                    success_counter += 1\n",
    "                    \n",
    "                    correct_name = vetted_list_using_initials[0]\n",
    "\n",
    "                    number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value)\n",
    "                    if type(number) == float:\n",
    "                        0==0\n",
    "                    else:\n",
    "                        number = add_correct_money(number)\n",
    "\n",
    "                    print(index, 'hi', full_num, name_player, vetted_list_using_initials, number, reason)\n",
    "                    pink_group_lookup_cases.at[index, 'Name(s) Found'] = correct_name\n",
    "                    pink_group_lookup_cases.at[index, 'Lookup Return Case'] = reason\n",
    "                    pink_group_lookup_cases.at[index, 'Market Value New'] = number\n",
    "                    pink_group_lookup_cases.at[index, 'Status New'] = 'Done'\n",
    "                    pink_group_lookup_cases.at[index, 'Status'] = 'SUCCESS'\n",
    "            \n",
    "        else:\n",
    "            done_cases += 1    \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "print(case_counter, success_counter, done_cases)\n",
    "\n",
    "        #for all these people, andthe U-20 guy.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guys to search for \n",
    "\n",
    "#A Gouiri\n",
    "#H Goitom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pink_group_lookup_cases.iterrows():\n",
    "    if row['ORIGINAL JERSEY'] == 'Henok Goitom':\n",
    "        pink_group_lookup_cases.at[index, 'Market Value New'] = 1200000.0\n",
    "        pink_group_lookup_cases.at[index, 'Lookup Return Case'] = 'Found in Curr Season'\n",
    "    if row['ORIGINAL JERSEY'] == 'N Tella':\n",
    "        pink_group_lookup_cases.at[index, 'Market Value New'] = 23000000.0\n",
    "        pink_group_lookup_cases.at[index, 'Lookup Return Case'] = 'Found in Curr Season'\n",
    "        pink_group_lookup_cases.at[index, 'Match Case'] = 'single'\n",
    "    if row['ORIGINAL JERSEY'] == 'F Koné':\n",
    "        pink_group_lookup_cases.at[index, 'Market Value New'] = 200000.0\n",
    "        pink_group_lookup_cases.at[index, 'Lookup Return Case'] = 'Found in Curr Season'\n",
    "        pink_group_lookup_cases.at[index, 'Match Case'] = 'single'\n",
    "        pink_group_lookup_cases.at[index, 'Name'] = 'Francis Koné'\n",
    "    if row['ORIGINAL JERSEY'] == 'A Gouiri':\n",
    "        pink_group_lookup_cases.at[index, 'Market Value New'] = 35000000.0\n",
    "        pink_group_lookup_cases.at[index, 'Lookup Return Case'] = 'Found in Curr Season'\n",
    "        pink_group_lookup_cases.at[index, 'Match Case'] = 'single'\n",
    "        pink_group_lookup_cases.at[index, 'Name'] = 'Amine Gouiri'\n",
    "    if row['ORIGINAL JERSEY'] == 'Henok Goitom' and row['Name'] == 0:\n",
    "        pink_group_lookup_cases.at[index, 'Market Value New'] = 600000.0\n",
    "        pink_group_lookup_cases.at[index, 'Lookup Return Case'] = 'Found in Curr Season'\n",
    "        pink_group_lookup_cases.at[index, 'Status New'] = 'Done'\n",
    "        pink_group_lookup_cases.at[index, 'Name(s) Found'] = 'Henok Goitom'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pink_group_lookup_cases.iterrows():\n",
    "    if row['ORIGINAL JERSEY'] == 'H Goitom':\n",
    "        pink_group_lookup_cases.at[index, 'ORIGINAL JERSEY'] = 'Henok Goitom'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pink_group_lookup_cases.iterrows():\n",
    "    if row['Nationality'] == 'Guadeloupe' or row['Nationality'] == 'Martinique':\n",
    "        pink_group_lookup_cases.at[index, 'Status New'] = 'Done'\n",
    "        pink_group_lookup_cases.at[index, 'Status'] = 'FAIL - NO DATA'\n",
    "    if row['Nationality'] == 'Congo':\n",
    "        pink_group_lookup_cases.at[index, 'Team Country Code'] = 'CG'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pink_group_lookup_cases.iterrows():\n",
    "    pink_group_lookup_cases.at[index, 'Name'] = pink_group_lookup_cases.at[index, 'Name(s) Found']\n",
    "    if row['Market Value New'] != 0:\n",
    "        #print(row['Market Value New'], row['Market Value'])\n",
    "        pink_group_lookup_cases.at[index, 'Market Value'] = pink_group_lookup_cases.at[index, 'Market Value New']\n",
    "    if row['Status'] == 'FAIL':\n",
    "        pink_group_lookup_cases.at[index, 'Status'] = 'SUCCESS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status\n",
       "SUCCESS           130\n",
       "FAIL - NO DATA     66\n",
       "FAIL - LARGE       28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pink_group_lookup_cases['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_group_lookup_cases.to_csv('pink_group_lookup_cases_DONE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyrillic Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_group_cyrillic = load_csv_dataset('April 25 - CONCACAF & CONMEBOL OUT - DATA CSVs/Pink Group/CONCACAF & CONMEBOL OUT - Cyrillic_Guys_Nobody_Found.csv')\n",
    "pink_group_cyrillic = pink_group_cyrillic.drop(columns={'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0'})\n",
    "pink_group_cyrillic = pink_group_cyrillic.rename(columns={'Match(es) Found': 'Name(s) Found'})\n",
    "pink_group_cyrillic['Status New'] = ''\n",
    "pink_group_cyrillic['Market Value New'] = 0\n",
    "pink_group_cyrillic['Lookup Return Case'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/z2xv57_n70l_szw_fr80j5km0000gn/T/ipykernel_48300/3226868144.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Niall McGinn' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  pink_group_cyrillic.at[39, 'Name(s) Found'] = 'Niall McGinn'\n"
     ]
    }
   ],
   "source": [
    "pink_group_cyrillic.at[39, 'Name(s) Found'] = 'Niall McGinn'\n",
    "pink_group_cyrillic.at[39, 'Status'] = 'SUCCESS'\n",
    "pink_group_cyrillic.at[39, 'Status New'] = 'Done'\n",
    "pink_group_cyrillic.at[39, 'Lookup Return Case'] = 'Found in Curr Season'\n",
    "pink_group_cyrillic.at[39, 'Market Value New'] = 700000\n",
    "pink_group_cyrillic.at[2, 'Name(s) Found'] = 'Martin Büchel'\n",
    "pink_group_cyrillic.at[2, 'Status'] = 'SUCCESS'\n",
    "pink_group_cyrillic.at[2, 'Status New'] = 'Done'\n",
    "pink_group_cyrillic.at[2, 'Lookup Return Case'] = 'Found in Curr Season'\n",
    "pink_group_cyrillic.at[2, 'Match Case'] = 'single'\n",
    "pink_group_cyrillic.at[39, 'Match Case'] = 'single'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 did not work 2014 0 Did Not Find in Curr Season, One Up, or One Down\n",
      "1 3 172 66\n"
     ]
    }
   ],
   "source": [
    "case_counter = 0\n",
    "done_cases = 0\n",
    "broken_counter = 0\n",
    "for index,row in pink_group_cyrillic.iterrows():\n",
    "    if row['Status New'] != 'Done':\n",
    "        this_found_name = row['English Name']\n",
    "        if this_found_name == 'L Kasharo':\n",
    "            this_found_name = 'L Casciaro'\n",
    "        elif this_found_name == 'F Witayoli':\n",
    "            this_found_name = 'F Vitaoli'\n",
    "        elif this_found_name == 'D Simonchini':\n",
    "            this_found_name = 'D Simoncini'\n",
    "        elif this_found_name == 'Asimoncini':\n",
    "            this_found_name = 'A Simoncini'\n",
    "        if index == 2:\n",
    "            this_found_name = 'Martin Büchel'\n",
    "        elif index == 39:\n",
    "            this_found_name = 'Niall McGinn'\n",
    "        elif this_found_name == 'E Vishnyakov':\n",
    "            this_found_name = 'Eduards Visnakovs'\n",
    "        elif this_found_name == 'A  Vishnyakov':\n",
    "            this_found_name = 'Aleksejs Visnakovs'\n",
    "        elif this_found_name == 'R Gurbanov':\n",
    "            this_found_name = 'Ruslan Qurbanov'\n",
    "        elif this_found_name == 'Aroyan':\n",
    "            this_found_name = 'Varazdat Haroyan'\n",
    "        elif this_found_name == 'Ceyhan Yildiz':\n",
    "            this_found_name = 'Seyhan Yildiz'\n",
    "        elif this_found_name == 'Garaev':\n",
    "            this_found_name = 'Qara Qaraev'\n",
    "        elif this_found_name == 'Karaev':\n",
    "            this_found_name = 'Qara Qaraev'\n",
    "        elif this_found_name == 'Dossajunior':\n",
    "            this_found_name = 'Dossa Júnior'\n",
    "        elif this_found_name == 'Armash':\n",
    "            this_found_name = 'Igor Armaş'\n",
    "        elif this_found_name == 'Ehri':\n",
    "            this_found_name = 'Yves Oehri'\n",
    "        elif this_found_name == 'Vieser':\n",
    "            this_found_name = 'Sandro Wieser'\n",
    "        elif this_found_name == 'Askovski':\n",
    "            this_found_name = 'Stefan Ashkovski'\n",
    "        elif this_found_name == 'Zhans':\n",
    "            this_found_name = 'Laurent Jans'\n",
    "        elif this_found_name == 'Grośowski':\n",
    "            this_found_name = 'Patrik Hrosovsky'\n",
    "        elif this_found_name == 'Tsaunya':\n",
    "            this_found_name = 'Aleksandrs Cauna'\n",
    "        elif this_found_name == 'Kazaishvili':\n",
    "            this_found_name = 'Valeri Qazaishvili'\n",
    "        elif this_found_name == 'Diomber':\n",
    "            this_found_name == 'Norbert Gyomber'\n",
    "        elif this_found_name == 'Colsen':\n",
    "            this_found_name = 'Klaemint Olsen'\n",
    "        elif this_found_name == 'Siquero':\n",
    "            this_found_name = 'Gabriel Cichero'\n",
    "        elif this_found_name == 'Kipchu':\n",
    "            this_found_name = 'Alexandru Chipciu'\n",
    "        elif this_found_name == 'Khalsti':\n",
    "            this_found_name = 'Markus Halsti'\n",
    "        elif this_found_name == 'Yuhas':\n",
    "            this_found_name = 'Roland Juhász'\n",
    "        elif this_found_name == 'Ogani':\n",
    "            this_found_name = 'Orel Dgani'\n",
    "        elif this_found_name == 'Mikhailovmmm':\n",
    "            this_found_name = 'Maxim Mihaliov'\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        nationality = row['Nationality']\n",
    "        \n",
    "        found_names_this_country = combined_df[combined_df['ORIGINAL JERSEY'] == this_found_name]['Name(s) Found'].unique()\n",
    "        if len(found_names_this_country) == 1:\n",
    "            case_counter += 1\n",
    "            #print(index, this_found_name, found_names_this_country)\n",
    "            full_num = row['Season']\n",
    "            country_code_this = row['Country Code']\n",
    "\n",
    "            correct_name = found_names_this_country[0]\n",
    "\n",
    "            number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value)\n",
    "            if type(number) == float:\n",
    "                0==0\n",
    "            else:\n",
    "                number = add_correct_money(number)\n",
    "            \n",
    "\n",
    "            if reason != 'Did Not Find in Curr Season, One Up, or One Down':\n",
    "                print(index, this_found_name, found_names_this_country, nationality, full_num, number, reason)\n",
    "                pink_group_cyrillic.at[index, 'Name(s) Found'] = correct_name\n",
    "                pink_group_cyrillic.at[index, 'Lookup Return Case'] = reason\n",
    "                pink_group_cyrillic.at[index, 'Market Value New'] = number\n",
    "                pink_group_cyrillic.at[index, 'Status New'] = 'Done'\n",
    "                pink_group_cyrillic.at[index, 'Status'] = 'SUCCESS'\n",
    "                pink_group_cyrillic.at[index, 'Match Case'] = 'single'\n",
    "            else:\n",
    "                if index == 146:\n",
    "                    print(index, 'did not work', full_num, number, reason)\n",
    "                else:\n",
    "                    print(index, 'did not work', full_num, number, reason)\n",
    "        else:\n",
    "            if len(found_names_this_country) == 0:\n",
    "                if this_found_name == '[]':\n",
    "                    broken_counter += 1\n",
    "                else:\n",
    "                    \n",
    "                    found_names_this_country = combined_df[combined_df['Nationality'] == nationality]['Name(s) Found'].unique()\n",
    "                    best_match_existing_data = threshold_player_match(this_found_name, found_names_this_country)[0]\n",
    "                    if len(best_match_existing_data) == 1:\n",
    "                        if best_match_existing_data == ['No matches found even with the lowest threshold.']:\n",
    "                            0==0\n",
    "                        else:\n",
    "                            \n",
    "                            vetted_group = vet_group_using_initials(this_found_name, this_found_name, best_match_existing_data)\n",
    "                            if this_found_name in vetted_group:\n",
    "                                vetted_group.remove(this_found_name)\n",
    "                            if len(vetted_group) != 0:\n",
    "                                case_counter += 1\n",
    "                                correct_name = vetted_group[0]\n",
    "                                print(index, this_found_name, row['ORIGINAL JERSEY'], correct_name, row['Nationality'], row['Match'], row['Date'])\n",
    "                                full_num = row['Season']\n",
    "                                country_code_this = row['Country Code']\n",
    "\n",
    "                                number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value)\n",
    "                                #print(player_this, reason, add_correct_money(number))\n",
    "\n",
    "                                #add a new row to lookup dataset 1 \n",
    "                                if type(number) == float:\n",
    "                                    0==0\n",
    "                                else:\n",
    "                                    number = add_correct_money(number)\n",
    "                                print('**')\n",
    "                                print(index, correct_name, number, reason)\n",
    "                                # if reason == 'Found in Curr Season':\n",
    "                                pink_group_cyrillic.at[index, 'Name(s) Found'] = correct_name\n",
    "                                pink_group_cyrillic.at[index, 'Status New'] = 'Done'\n",
    "                                pink_group_cyrillic.at[index, 'Market Value New'] = number\n",
    "                                pink_group_cyrillic.at[index, 'Match Case'] = 'single'\n",
    "                                pink_group_cyrillic.at[index, 'Lookup Return Case'] = reason\n",
    "                                success_counter += 1\n",
    "                                \n",
    "            else:\n",
    "                print(index, 'yo', this_found_name, row['Date'], row['Match'], found_names_this_country)\n",
    "                \n",
    "    else:\n",
    "        done_cases += 1\n",
    "            \n",
    "print(case_counter, broken_counter, success_counter, done_cases)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pink_group_cyrillic.iterrows():\n",
    "    \n",
    "    if row['ORIGINAL JERSEY'] == '2. Шано':\n",
    "        pink_group_cyrillic.at[index, 'ORIGINAL JERSEY'] = 'Maxime Chanot'\n",
    "        pink_group_cyrillic.at[index, 'Name(s) Found'] = 'Maxime Chanot'\n",
    "    elif row['ORIGINAL JERSEY'] == '1. Пачовски':\n",
    "        pink_group_cyrillic.at[index, 'ORIGINAL JERSEY'] = 'Tome Pacovski'\n",
    "        pink_group_cyrillic.at[index, 'Name(s) Found'] = 'Tome Pacovski'\n",
    "    elif row['ORIGINAL JERSEY'] == '2. Нес':\n",
    "        pink_group_cyrillic.at[index, 'ORIGINAL JERSEY'] = 'Jónas Tór Naes'\n",
    "        pink_group_cyrillic.at[index, 'Name(s) Found'] = 'Jónas Tór Naes'\n",
    "    elif row['ORIGINAL JERSEY'] == '23. Логвиненко':\n",
    "        pink_group_cyrillic.at[index, 'ORIGINAL JERSEY'] = 'Yuriy Logvinenko'\n",
    "        pink_group_cyrillic.at[index, 'Name(s) Found'] = 'Yuriy Logvinenko'\n",
    "    elif row['ORIGINAL JERSEY'] == '5. Дьомбер':\n",
    "        pink_group_cyrillic.at[index, 'ORIGINAL JERSEY'] = 'Norbert Gyömbér'\n",
    "        pink_group_cyrillic.at[index, 'Name(s) Found'] = 'Norbert Gyömbér'\n",
    "    elif row['ORIGINAL JERSEY'] == '18. Уронен':\n",
    "        pink_group_cyrillic.at[index, 'ORIGINAL JERSEY'] = 'Jere Uronen'\n",
    "        pink_group_cyrillic.at[index, 'Name(s) Found'] = 'Jere Uronen'\n",
    "    elif row['ORIGINAL JERSEY'] == '3. Гурман':\n",
    "        pink_group_cyrillic.at[index, 'ORIGINAL JERSEY'] = 'Mark Gurman'\n",
    "        pink_group_cyrillic.at[index, 'Name(s) Found'] = 'Mark Gurman'\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pink_group_cyrillic.iterrows():\n",
    "    if row['ORIGINAL JERSEY'] == 'Norbert Gyömbér':\n",
    "        pink_group_cyrillic.at[index, 'Name(s) Found'] = 'Norbert Gyomber'\n",
    "        pink_group_cyrillic.at[index, 'ORIGINAL JERSEY'] = 'Norbert Gyomber'\n",
    "    elif row['ORIGINAL JERSEY'] == 'Tome Pacovski':\n",
    "        pink_group_cyrillic.at[index, 'Name(s) Found'] = 'Tome Pačovski'\n",
    "        pink_group_cyrillic.at[index, 'ORIGINAL JERSEY'] = 'Tome Pačovski'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 104\n"
     ]
    }
   ],
   "source": [
    "done_cases = 0\n",
    "success_counter = 0\n",
    "for index, row in pink_group_cyrillic.iterrows():\n",
    "    if row['Status New'] != 'Done':\n",
    "        name = row['Name(s) Found']\n",
    "        full_num = row['Season']\n",
    "        country_code_this = row['Country Code']\n",
    "        dataset_nationality = leagues_value[(leagues_value['Team 1 Code'] == country_code_this) & \n",
    "                                    (leagues_value['Season'].isin([full_num, full_num + 1, full_num - 1]))]['Name'].unique()\n",
    "        if name in dataset_nationality:\n",
    "            correct_name = name\n",
    "            \n",
    "            print(index, name)\n",
    "\n",
    "            number, reason = find_in_transfermarkt(correct_name, full_num, country_code_this, leagues_value)\n",
    "            #print(player_this, reason, add_correct_money(number))\n",
    "\n",
    "            #add a new row to lookup dataset 1 \n",
    "            if type(number) == float:\n",
    "                0==0\n",
    "            else:\n",
    "                number = add_correct_money(number)\n",
    "            print('**')\n",
    "            print(index, correct_name, number, reason)\n",
    "            # if reason == 'Found in Curr Season':\n",
    "            pink_group_cyrillic.at[index, 'Name(s) Found'] = correct_name\n",
    "            pink_group_cyrillic.at[index, 'Status New'] = 'Done'\n",
    "            pink_group_cyrillic.at[index, 'Market Value New'] = number\n",
    "            pink_group_cyrillic.at[index, 'Match Case'] = 'single'\n",
    "            pink_group_cyrillic.at[index, 'Lookup Return Case'] = reason\n",
    "            success_counter += 1\n",
    "        #print(index, row['ORIGINAL JERSEY'], row['Nationality'], row['Match'], row['Date'])\n",
    "    else:\n",
    "        done_cases += 1\n",
    "\n",
    "print(success_counter, done_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DF index</th>\n",
       "      <th>Match ID</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Date</th>\n",
       "      <th>Match</th>\n",
       "      <th>Season</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>ORIGINAL JERSEY</th>\n",
       "      <th>English Name</th>\n",
       "      <th>Name(s) Found</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status New</th>\n",
       "      <th>Market Value New</th>\n",
       "      <th>Lookup Return Case</th>\n",
       "      <th>Match Case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DF index, Match ID, Competition, Date, Match, Season, Nationality, Country Code, ORIGINAL JERSEY, English Name, Name(s) Found, Status, Status New, Market Value New, Lookup Return Case, Match Case]\n",
       "Index: []"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pink_group_cyrillic[pink_group_cyrillic['ORIGINAL JERSEY'] == '3. Гурман']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_group_cyrillic.to_csv('pink_group_cyrillic_dudes_DONE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGINAL JERSEY\n",
       "5. Агиус Э.         2\n",
       "10. Сливка          2\n",
       "16. Алисами         2\n",
       "2. Малый            2\n",
       "3. Жута             2\n",
       "15. Фере            2\n",
       "18. Жута            2\n",
       "17. Сынмэртян       2\n",
       "13. Жоашим          2\n",
       "16. Сливка          2\n",
       "11. Алиев           2\n",
       "22. Томсен Я.Л.     2\n",
       "15. Хведукас        2\n",
       "7. Чеснаускис Д.    1\n",
       "8. Гыртымов         1\n",
       "17. Петрович        1\n",
       "3. Дембер           1\n",
       "17.  Петрович       1\n",
       "4. Петрович         1\n",
       "5. Япасто           1\n",
       "19. Кабрера Дж.     1\n",
       "23. Шимич           1\n",
       "6. Гусейнов Б.      1\n",
       "2. К.Мартинс        1\n",
       "9. Кибер            1\n",
       "16. Фло             1\n",
       "19. Кибер           1\n",
       "3. Родич            1\n",
       "20. Время           1\n",
       "17. Оникэ           1\n",
       "12. Бичер           1\n",
       "13. С.Митрович      1\n",
       "13. К.Оганесян      1\n",
       "4. Н.Вукчевич       1\n",
       "14. Нан Ваи Мин     1\n",
       "15. Христов         1\n",
       "7. Джавадов         1\n",
       "22. Г.Илиев         1\n",
       "4. Ф.Витайоли       1\n",
       "11. Чезарини        1\n",
       "5. Капилото         1\n",
       "22. Хурме           1\n",
       "3. Глостер          1\n",
       "6. Хансон           1\n",
       "4. Лукин            1\n",
       "13. Оганесян        1\n",
       "2. К.Мартинес       1\n",
       "7. Файла            1\n",
       "5. Раку             1\n",
       "18. Кристенсен      1\n",
       "7. Фэйла            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pink_group_cyrillic[pink_group_cyrillic['Status New'] != 'Done']['ORIGINAL JERSEY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Combined DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/z2xv57_n70l_szw_fr80j5km0000gn/T/ipykernel_48300/1791224083.py:49: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "combined_df = load_csv_dataset('combined_df_may_1.csv')\n",
    "combined_df = combined_df.drop(columns={'Unnamed: 0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "tally = 0\n",
    "for index, row in combined_df.iterrows():\n",
    "    if combined_df.at[index, \"Name(s) Found\"].startswith('['):\n",
    "\n",
    "        if len(eval(combined_df.at[index, \"Name(s) Found\"])) > 1:\n",
    "            print(index, 'oh shit')\n",
    "        else:\n",
    "            tally += 1\n",
    "            print(index, combined_df.at[index, \"Name(s) Found\"], eval(combined_df.at[index, \"Name(s) Found\"])[0])\n",
    "            combined_df.at[index, \"Name(s) Found\"] = eval(combined_df.at[index, \"Name(s) Found\"])[0]\n",
    "    elif type(combined_df.at[index, \"Name(s) Found\"]) == list:\n",
    "        0==0\n",
    "        #print(index, combined_df.at[index, \"Name(s) Found\"])\n",
    "print(tally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
